# –ó–∞–¥–∞–Ω–∏–µ 1

------------------------------------------------------------------------

–°–æ–∑–¥–∞—Ç—å —Ä–µ–≥—Ä–µ—Å—Å–∏–æ–Ω–Ω—É—é –º–æ–¥–µ–ª—å (–∏–ª–∏ –Ω–µ—Å–∫–æ–ª—å–∫–æ –º–æ–¥–µ–ª–µ–π), –∫–æ—Ç–æ—Ä–∞—è –æ–ø–∏—Å—ã–≤–∞–ª–∞ –±—ã —Å–≤—è–∑—å:

-   —Å—Ä–µ–¥–Ω–µ–≥–æ —Ä–∞–¥–∏—É—Å–∞ –æ–ø—É—Ö–æ–ª–∏ –∏ —Å—Ä–µ–¥–Ω–µ–π –ø–ª–æ—â–∞–¥–∏;

-   —Å—Ä–µ–¥–Ω–µ–≥–æ –ø–µ—Ä–∏–º–µ—Ç—Ä–∞;

-   —Å—Ä–µ–¥–Ω–µ–π —Å–∏–º–º–µ—Ç—Ä–∏—á–Ω–æ—Å—Ç–∏.

–ü–æ—Å—Ç—Ä–æ–π—Ç–µ –≥—Ä–∞—Ñ–∏–∫ (–∏–ª–∏ –≥—Ä–∞—Ñ–∏–∫–∏, –µ—Å–ª–∏ –º–æ–¥–µ–ª–µ–π –Ω–µ—Å–∫–æ–ª—å–∫–æ), –Ω–∞ –∫–æ—Ç–æ—Ä–æ–º –æ—Ç—Ä–∞–∑–∏—Ç–µ —Ä–µ–≥—Ä–µ—Å—Å–∏–æ–Ω–Ω—É—é –ø—Ä—è–º—É—é, –∏ –ø—Ä–æ–∫–æ–º–º–µ–Ω—Ç–∏—Ä—É–π—Ç–µ —Å–≤–æ–∏ –Ω–∞—Ö–æ–¥–∫–∏.


–ú–µ—Ç–æ–¥—ã:
- Univariate –∏ Multivariate —Ä–µ–≥—Ä–µ—Å—Å–∏–∏

- –ú–æ–¥–µ–ª–∏: –õ–∏–Ω–µ–π–Ω–∞—è —Ä–µ–≥—Ä–µ—Å—Å–∏—è, –ü–æ–ª–∏–Ω–æ–º–∏–∞–ª—å–Ω–∞—è —Ä–µ–≥—Ä–µ—Å—Å–∏—è (2-–π —Å—Ç–µ–ø–µ–Ω–∏), Random Forest, XGBoost

Univariate regression

```{r}
library(ggplot2)
library(dplyr)
library(caret)
library(Metrics)
library(randomForest)
library(xgboost)
library(broom)

df <- read.csv("wisconsin_breast_cancer.csv")
features <- c("area_mean", "perimeter_mean", "symmetry_mean")
target <- "radius_mean"

compute_metrics <- function(true, pred) {
  data.frame(
    MAE = mae(true, pred),
    MSE = mse(true, pred),
    RMSE = rmse(true, pred),
    R2 = R2(pred, true),
    stringsAsFactors = FALSE
  )
}

set.seed(42)

model_types <- list(
  "Linear" = function(train) lm(Y ~ X, data = train),
  "Polynomial" = function(train) lm(Y ~ poly(X, 2), data = train),
  "Random Forest" = function(train) randomForest(Y ~ X, data = train),
  "XGBoost" = function(train) {
    dtrain <- xgb.DMatrix(as.matrix(train$X), label = train$Y)
    xgb.train(list(objective = "reg:squarederror", max_depth = 3, eta = 0.1), dtrain, nrounds = 100)
  }
)

results_uni <- list()

par(mfrow = c(1, 3))

for (model_name in names(model_types)) {
  for (feature in features) {
    data_sub <- df[, c(feature, target)]
    names(data_sub) <- c("X", "Y")
    
    idx <- createDataPartition(data_sub$Y, p = 0.8, list = FALSE)
    train <- data_sub[idx, ]
    test <- data_sub[-idx, ]
    
    model <- model_types[[model_name]](train)
    
    pred <- if (model_name == "XGBoost") {
      predict(model, xgb.DMatrix(as.matrix(test$X)))
    } else {
      predict(model, newdata = test)
    }
    
    metrics <- compute_metrics(test$Y, pred)
    metrics$Model <- model_name
    metrics$Feature <- feature
    results_uni[[length(results_uni) + 1]] <- metrics
    
    plot(test$X, test$Y, main = paste(feature, "‚Üí", target), pch = 16, col = rgb(0,0,0,0.4),
         xlab = feature, ylab = target)
    points(test$X, pred, col = "red", pch = 16)
    legend("topleft", legend = c("Actual", "Predicted"), col = c("black", "red"), pch = 16)
  }
}

df_uni <- do.call(rbind, results_uni) %>% 
  arrange(Feature, desc(R2)) %>%
  mutate(across(where(is.numeric), round, 4))

print(df_uni)
```

area_mean –∏ perimeter_mean –ø—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞—é—Ç radius_mean —Å –æ—á–µ–Ω—å –≤—ã—Å–æ–∫–æ–π —Ç–æ—á–Ω–æ—Å—Ç—å—é (R¬≤ > 0.98).

symmetry_mean —Å–ª–∞–±–æ –∫–æ—Ä—Ä–µ–ª–∏—Ä—É–µ—Ç —Å —Ü–µ–ª–µ–≤—ã–º –ø—Ä–∏–∑–Ω–∞–∫–æ–º (–Ω–∏–∑–∫–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è R¬≤).



–ü—Ä–æ–≤–µ—Ä–∏–º Multivariate regression:

```{r}
set.seed(42)

X <- df[, features]
y <- df[, target]

idx <- createDataPartition(y, p = 0.8, list = FALSE)
X_train <- X[idx, ]
X_test  <- X[-idx, ]
y_train <- y[idx]
y_test  <- y[-idx]

model_types_multi <- list(
  "Linear" = function() lm(y_train ~ ., data = X_train),
  "Polynomial" = function() lm(y_train ~ poly(area_mean, 2) + poly(perimeter_mean, 2) + poly(symmetry_mean, 2), data = X_train),
  "Random Forest" = function() randomForest(y_train ~ ., data = X_train),
  "XGBoost" = function() {
    dtrain <- xgb.DMatrix(as.matrix(X_train), label = y_train)
    xgb.train(list(objective = "reg:squarederror", max_depth = 3, eta = 0.1), dtrain, nrounds = 100)
  }
)

results_multi <- list()

for (model_name in names(model_types_multi)) {
  model <- model_types_multi[[model_name]]()
  
  pred <- if (model_name == "XGBoost") {
    predict(model, xgb.DMatrix(as.matrix(X_test)))
  } else {
    predict(model, newdata = X_test)
  }
  
  metrics <- compute_metrics(y_test, pred)
  metrics$Model <- model_name
  results_multi[[length(results_multi) + 1]] <- metrics
  
  print(
    ggplot(data.frame(y_test, pred), aes(x = y_test, y = pred)) +
      geom_point(alpha = 0.5) +
      geom_abline(slope = 1, intercept = 0, color = "red") +
      ggtitle(paste(model_name, " ‚Äî All features ‚Üí", target)) +
      xlab("Actual") + ylab("Predicted") +
      theme_minimal()
  )
}

df_multi <- do.call(rbind, results_multi) %>%
  mutate(across(where(is.numeric), round, 4)) %>%
  arrange(desc(R2))

print(df_multi)

```

–ö–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–∞–µ—Ç –≤—ã—Å–æ–∫—É—é –ª–∏–Ω–µ–π–Ω—É—é –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç—å radius_mean –æ—Ç area_mean –∏ perimeter_mean.

–ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ —Å–ª–æ–∂–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π —Ç–∏–ø–∞ Random Forest –∏ XGBoost –Ω–µ –¥–∞—ë—Ç —Å—É—â–µ—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ –ø—Ä–∏—Ä–æ—Å—Ç–∞ –∫–∞—á–µ—Å—Ç–≤–∞ –ø–æ —Å—Ä–∞–≤–Ω–µ–Ω–∏—é —Å –ª–∏–Ω–µ–π–Ω—ã–º–∏ –º–æ–¥–µ–ª—è–º–∏.

```{r}
library(ggplot2)
library(Metrics)

# –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö
df <- read.csv("wisconsin_breast_cancer.csv")

# –§—É–Ω–∫—Ü–∏—è –¥–ª—è —Ä–∞—Å—á—ë—Ç–∞, –º–µ—Ç—Ä–∏–∫ –∏ –≥—Ä–∞—Ñ–∏–∫–∞
evaluate_estimation <- function(true_values, predicted_values, true_label, pred_label) {
  cat(sprintf("\n–†–∞—Å—á—ë—Ç %s —á–µ—Ä–µ–∑ %s:\n", true_label, pred_label))
  cat(sprintf("MAE:  %.4f\n", mae(true_values, predicted_values)))
  cat(sprintf("MSE:  %.4f\n", mse(true_values, predicted_values)))
  cat(sprintf("RMSE: %.4f\n", rmse(true_values, predicted_values)))
  cat(sprintf("R¬≤:   %.4f\n", R2(predicted_values, true_values)))
  
  ggplot(data.frame(True = true_values, Predicted = predicted_values), aes(x = True, y = Predicted)) +
    geom_point(alpha = 0.6) +
    geom_abline(slope = 1, intercept = 0, color = "red", linetype = "dashed") +
    labs(
      x = paste("–§–∞–∫—Ç–∏—á–µ—Å–∫–∏–π", true_label),
      y = paste("–†–∞—Å—Å—á–∏—Ç–∞–Ω–Ω—ã–π", pred_label),
      title = paste("–°—Ä–∞–≤–Ω–µ–Ω–∏–µ:", true_label, "vs", pred_label)
    ) +
    theme_minimal() +
    theme(plot.title = element_text(hjust = 0.5))
}

# –û—Ü–µ–Ω–∫–∞ radius_mean —á–µ—Ä–µ–∑ area_mean
df$radius_estimated <- sqrt(df$area_mean / pi)
p1 <- evaluate_estimation(df$radius_mean, df$radius_estimated, "radius_mean", "radius_estimated")

# –û—Ü–µ–Ω–∫–∞ perimeter_mean —á–µ—Ä–µ–∑ radius_mean
df$perimeter_estimated <- 2 * pi * df$radius_mean
p2 <- evaluate_estimation(df$perimeter_mean, df$perimeter_estimated, "perimeter_mean", "perimeter_estimated")

# –í—ã–≤–æ–¥ –≥—Ä–∞—Ñ–∏–∫–æ–≤
p1
p2

```

r\^2 –±–ª–∏–∑–æ–∫ –∫ –µ–¥–∏–Ω–∏—Ü–µ


–ú—ã —É—Å—Ç–∞–Ω–æ–≤–∏–ª–∏, —á—Ç–æ —Ç–∞–∫–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –∫–∞–∫ area_mean, perimeter_mean –∏ radius_mean –º–æ–∂–Ω–æ –ª–µ–≥–∫–æ –≤—ã—á–∏—Å–ª—è—Ç—å –¥—Ä—É–≥ —á–µ—Ä–µ–∑ –¥—Ä—É–≥–∞, –±–ª–∞–≥–æ–¥–∞—Ä—è –∏—Ö —Ç–µ—Å–Ω–æ–π —Ñ–∏–∑–∏–∫–æ-–º–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–æ–π —Å–≤—è–∑–∏.

–û–¥–Ω–∞–∫–æ –≤ –¥–∞—Ç–∞—Å–µ—Ç–µ —Ç–∞–∫–∂–µ –ø—Ä–∏—Å—É—Ç—Å—Ç–≤—É–µ—Ç –ø—Ä–∏–∑–Ω–∞–∫ symmetry_mean, –∫–æ—Ç–æ—Ä—ã–π –¥–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä—É–µ—Ç —Å–ª–∞–±—É—é –ª–∏–Ω–µ–π–Ω—É—é –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç—å —Å –æ—Å—Ç–∞–ª—å–Ω—ã–º–∏ –ø—Ä–∏–∑–Ω–∞–∫–∞–º–∏.
–° –∏—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å—Å–∫–æ–π —Ç–æ—á–∫–∏ –∑—Ä–µ–Ω–∏—è –∏–Ω—Ç–µ—Ä–µ—Å–Ω–æ –ø—Ä–æ–≤–µ—Ä–∏—Ç—å, –≤–æ–∑–º–æ–∂–Ω–æ –ª–∏ –µ–≥–æ –Ω–∞–¥—ë–∂–Ω–æ –ø—Ä–µ–¥—Å–∫–∞–∑–∞—Ç—å.

–ü–æ—Å–∫–æ–ª—å–∫—É –∏–Ω–¥–∏–≤–∏–¥—É–∞–ª—å–Ω–∞—è –∫–æ—Ä—Ä–µ–ª—è—Ü–∏—è symmetry_mean —Å –æ—Å—Ç–∞–ª—å–Ω—ã–º–∏ –ø—Ä–∏–∑–Ω–∞–∫–∞–º–∏ –Ω–∏–∑–∫–∞—è, –ø–µ—Ä–µ–π–¥–µ–º —Å—Ä–∞–∑—É –∫ –º—É–ª—å—Ç–∏—Ñ–∞–∫—Ç–æ—Ä–Ω–æ–º—É –º–æ–¥–µ–ª–∏—Ä–æ–≤–∞–Ω–∏—é (Multivariate Regression).

```{r}
library(ggplot2)
library(caret)
library(randomForest)
library(xgboost)
library(Metrics)

# –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö
df <- read.csv("wisconsin_breast_cancer.csv")
features <- c("area_mean", "perimeter_mean", "radius_mean")
target <- "symmetry_mean"

# –î–µ–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö
set.seed(42)
train_idx <- createDataPartition(df[[target]], p = 0.8, list = FALSE)
X_train <- df[train_idx, features]
X_test  <- df[-train_idx, features]
y_train <- df[train_idx, target]
y_test  <- df[-train_idx, target]

# –§—É–Ω–∫—Ü–∏—è –º–µ—Ç—Ä–∏–∫
compute_metrics <- function(true, pred) {
  data.frame(
    MAE = mae(true, pred),
    MSE = mse(true, pred),
    RMSE = rmse(true, pred),
    R2 = R2(pred, true)
  )
}

# –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π
models <- list(
  "Linear Regression" = function() lm(y_train ~ ., data = X_train),
  "Polynomial Regression" = function() lm(y_train ~ poly(area_mean, 2) + poly(perimeter_mean, 2) + poly(radius_mean, 2), data = X_train),
  "Random Forest" = function() randomForest(y_train ~ ., data = X_train),
  "XGBoost" = function() {
    dtrain <- xgb.DMatrix(data = as.matrix(X_train), label = y_train)
    xgb.train(list(objective = "reg:squarederror", max_depth = 3, eta = 0.1), dtrain, nrounds = 100)
  }
)

# –û–±—É—á–µ–Ω–∏–µ –∏ –æ—Ü–µ–Ω–∫–∞
results <- list()

for (name in names(models)) {
  model <- models[[name]]()
  preds <- if (name == "XGBoost") predict(model, xgb.DMatrix(as.matrix(X_test))) else predict(model, newdata = X_test)
  
  metrics <- compute_metrics(y_test, preds)
  metrics$Model <- name
  results[[length(results) + 1]] <- metrics
  
  print(ggplot(data.frame(Actual = y_test, Predicted = preds), aes(x = Actual, y = Predicted)) +
    geom_point(alpha = 0.6) +
    geom_abline(slope = 1, intercept = 0, color = "red", linetype = "dashed") +
    labs(title = paste(name, " ‚Äî", target), x = "–§–∞–∫—Ç–∏—á–µ—Å–∫–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ", y = "–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω–æ–µ") +
    theme_minimal())
}

# –ò—Ç–æ–≥–æ–≤–∞—è —Ç–∞–±–ª–∏—Ü–∞
results_df <- do.call(rbind, results) %>% 
  mutate(across(where(is.numeric), round, 4)) %>%
  arrange(desc(R2))

cat("\nüìä –ò—Ç–æ–≥–æ–≤—ã–µ –º–µ—Ç—Ä–∏–∫–∏:\n")
print(results_df)

```

–ü–æ–∫–∞–∑–∞—Ç–µ–ª—å R¬≤ –¥–ª—è Polynomial Regression —Å–æ—Å—Ç–∞–≤–∏–ª ~0.4013 ‚Äî –ª—É—á—à–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç —Å—Ä–µ–¥–∏ –ø—Ä–æ—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π.

–≠—Ç–æ –æ–∑–Ω–∞—á–∞–µ—Ç, —á—Ç–æ ~40% –¥–∏—Å–ø–µ—Ä—Å–∏–∏ –ø—Ä–∏–∑–Ω–∞–∫–∞ symmetry_mean –æ–±—ä—è—Å–Ω—è–µ—Ç—Å—è –Ω–∞—à–µ–π –º–æ–¥–µ–ª—å—é ‚Äî –¥–ª—è –º–µ–¥–∏—Ü–∏–Ω—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö —Ç–∞–∫–æ–π —É—Ä–æ–≤–µ–Ω—å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è —Å—á–∏—Ç–∞–µ—Ç—Å—è —É–º–µ—Ä–µ–Ω–Ω—ã–º.

–õ–∏–Ω–µ–π–Ω—ã–µ –∏ –ª–µ—Å–Ω—ã–µ –º–æ–¥–µ–ª–∏ —Å–ø—Ä–∞–≤–∏–ª–∏—Å—å –∑–∞–º–µ—Ç–Ω–æ —Ö—É–∂–µ.



–î–æ–±–∞–≤–ª–µ–Ω–∏–µ –≤—Å–µ—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –≤ –º–æ–¥–µ–ª—å.
–ß—Ç–æ–±—ã –ø–æ–ø—ã—Ç–∞—Ç—å—Å—è —É–ª—É—á—à–∏—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç, –º—ã —Ä–∞—Å—à–∏—Ä—è–µ–º –≤—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ, –≤–∫–ª—é—á–∞—è –≤—Å–µ –≤–æ–∑–º–æ–∂–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ (–∑–∞ –∏—Å–∫–ª—é—á–µ–Ω–∏–µ–º –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä–æ–≤ –∏ —Ü–µ–ª–µ–≤–æ–≥–æ –ø—Ä–∏–∑–Ω–∞–∫–∞).

```{r}
library(caret)
library(randomForest)
library(xgboost)
library(Metrics)
library(ggplot2)

df <- read.csv("wisconsin_breast_cancer.csv")
df <- df[, colSums(is.na(df)) == 0]

target <- "symmetry_mean"
X <- df[, setdiff(names(df), c("diagnosis", "id", target))]
y <- df[, target]

set.seed(42)
trainIndex <- createDataPartition(y, p = .8, list = FALSE)
X_train <- X[trainIndex, ]
X_test  <- X[-trainIndex, ]
y_train <- y[trainIndex]
y_test  <- y[-trainIndex]

compute_metrics <- function(true, pred) {
  data.frame(
    MAE = mae(true, pred),
    MSE = mse(true, pred),
    RMSE = rmse(true, pred),
    R2 = R2(pred, true)
  )
}

model_defs <- list(
  "Linear Regression" = function() lm(y_train ~ ., data = X_train),
  "Polynomial Regression" = function() lm(y_train ~ poly(area_mean, 2) + poly(perimeter_mean, 2) + poly(radius_mean, 2), data = X_train),
  "Random Forest" = function() randomForest(y_train ~ ., data = X_train),
  "XGBoost" = function() {
    dtrain <- xgb.DMatrix(data = as.matrix(X_train), label = y_train)
    param <- list(objective = "reg:squarederror", max_depth = 3, eta = 0.1)
    model <- xgb.train(param, dtrain, nrounds = 100)
    model
  }
)

saved_models <- list()
results <- list()

for (model_name in names(model_defs)) {
  print(paste("\n======", model_name, "====="))
  
  model_creator <- model_defs[[model_name]]
  model <- model_creator()
  
  if (model_name == "XGBoost") {
    dtest <- xgb.DMatrix(data = as.matrix(X_test))
    pred <- predict(model, dtest)
  } else {
    pred <- predict(model, newdata = X_test)
  }
  
  saved_models[[model_name]] <- model
  
  metrics <- compute_metrics(y_test, pred)
  metrics$Model <- model_name
  results[[length(results) + 1]] <- metrics
  
  print(ggplot(data.frame(y_test, pred), aes(x = y_test, y = pred)) +
    geom_point(alpha = 0.6) +
    geom_abline(slope = 1, intercept = 0, col = "red", linetype = "dashed") +
    ggtitle(paste(model_name, " ‚Äî All Features ‚Üí", target)) +
    xlab("Actual") + ylab("Predicted") +
    theme_minimal() +
    theme(plot.title = element_text(hjust = 0.5)))
}

results_df <- do.call(rbind, results)
results_df$Model <- as.character(results_df$Model)  # Ensure Model is character
results_df <- results_df[order(-results_df$R2), ]  # Sort by R2 descending

numeric_cols <- sapply(results_df, is.numeric)
results_df[numeric_cols] <- round(results_df[numeric_cols], 4)

cat("\n –ú–µ—Ç—Ä–∏–∫–∏ –í–∞—Ä–∏–∞–Ω—Ç–∞ 2:\n")
print(results_df)

```

–ü—Ä–∏ –¥–æ–±–∞–≤–ª–µ–Ω–∏–∏ –≤—Å–µ—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –∫–∞—á–µ—Å—Ç–≤–æ –º–æ–¥–µ–ª–µ–π —Å—É—â–µ—Å—Ç–≤–µ–Ω–Ω–æ —É–ª—É—á—à–∏–ª–æ—Å—å.

–û–¥–Ω–∞–∫–æ, –¥–∞–ª—å–Ω–µ–π—à–∏–π –∞–Ω–∞–ª–∏–∑ –≤–∞–∂–Ω–æ—Å—Ç–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –ø–æ–∫–∞–∑–∞–ª, —á—Ç–æ –Ω–∞ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ —Å–∏–ª—å–Ω–µ–µ –≤—Å–µ–≥–æ –≤–ª–∏—è–µ—Ç symmetry_worst.

```{r}
xgb_importance <- xgb.importance(model = saved_models[["XGBoost"]])

print(xgb_importance)

xgb.plot.importance(importance_matrix = xgb_importance, 
                    top_n = 10, 
                    main = "Top 10 Most Important Features for XGBoost")

```

–ß—Ç–æ–±—ã –∏—Å–∫–ª—é—á–∏—Ç—å —ç—Ñ—Ñ–µ–∫—Ç "–ø–æ–¥—Å–∫–∞–∑–∫–∏", –º—ã —É–¥–∞–ª—è–µ–º symmetry_worst –∏ –ø–µ—Ä–µ–æ–±—É—á–∞–µ–º –º–æ–¥–µ–ª–∏.

–†–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ–∂–∏–¥–∞–µ–º–æ —Å–Ω–∏–∑–∏–ª–∏—Å—å, –æ–¥–Ω–∞–∫–æ –º–æ–¥–µ–ª–∏ –≤—Å—ë –µ—â—ë –ø–æ–∫–∞–∑—ã–≤–∞—é—Ç –Ω–µ–∫–æ—Ç–æ—Ä–æ–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞—Ç–µ–ª—å–Ω–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ.

```{r}
library(caret)
library(randomForest)
library(xgboost)
library(Metrics)
library(ggplot2)

df <- read.csv("wisconsin_breast_cancer.csv")
df <- df[, colSums(is.na(df)) == 0]

target <- "symmetry_mean"
X <- df[, setdiff(names(df), c("diagnosis", "id", "symmetry_worst", target))]
y <- df[, target]

set.seed(42)
trainIndex <- createDataPartition(y, p = .8, list = FALSE)
X_train <- X[trainIndex, ]
X_test  <- X[-trainIndex, ]
y_train <- y[trainIndex]
y_test  <- y[-trainIndex]

compute_metrics <- function(true, pred) {
  data.frame(
    MAE = mae(true, pred),
    MSE = mse(true, pred),
    RMSE = rmse(true, pred),
    R2 = R2(pred, true)
  )
}

model_defs <- list(
  "Linear Regression" = function() lm(y_train ~ ., data = X_train),
  "Polynomial Regression" = function() lm(y_train ~ poly(area_mean, 2) + poly(perimeter_mean, 2) + poly(radius_mean, 2), data = X_train),
  "Random Forest" = function() randomForest(y_train ~ ., data = X_train),
  "XGBoost" = function() {
    dtrain <- xgb.DMatrix(data = as.matrix(X_train), label = y_train)
    param <- list(objective = "reg:squarederror", max_depth = 3, eta = 0.1)
    model <- xgb.train(param, dtrain, nrounds = 100)
    model
  }
)

saved_models <- list()
results <- list()

for (model_name in names(model_defs)) {
  print(paste("\n======", model_name, "====="))

  model_creator <- model_defs[[model_name]]
  model <- model_creator()
  
  if (model_name == "XGBoost") {
    dtest <- xgb.DMatrix(data = as.matrix(X_test))
    pred <- predict(model, dtest)
  } else {
    pred <- predict(model, newdata = X_test)
  }
  
  saved_models[[model_name]] <- model
  metrics <- compute_metrics(y_test, pred)
  metrics$Model <- model_name
  results[[length(results) + 1]] <- metrics
  
  print(ggplot(data.frame(y_test, pred), aes(x = y_test, y = pred)) +
    geom_point(alpha = 0.6) +
    geom_abline(slope = 1, intercept = 0, col = "red", linetype = "dashed") +
    ggtitle(paste(model_name, " ‚Äî All Features ‚Üí", target)) +
    xlab("Actual") + ylab("Predicted") +
    theme_minimal() +
    theme(plot.title = element_text(hjust = 0.5)))
}

results_df <- do.call(rbind, results)
results_df$Model <- as.character(results_df$Model)  # Ensure Model is character
results_df <- results_df[order(-results_df$R2), ]  # Sort by R2 descending

numeric_cols <- sapply(results_df, is.numeric)
results_df[numeric_cols] <- round(results_df[numeric_cols], 4)

cat("\n –ú–µ—Ç—Ä–∏–∫–∏ –í–∞—Ä–∏–∞–Ω—Ç–∞ 2:\n")
print(results_df)
```

–ó–Ω–∞—á–µ–Ω–∏–µ symmetry_mean –º–æ–∂–Ω–æ —á–∞—Å—Ç–∏—á–Ω–æ –ø—Ä–µ–¥—Å–∫–∞–∑–∞—Ç—å –ø–æ –±–∞–∑–æ–≤—ã–º –≥–µ–æ–º–µ—Ç—Ä–∏—á–µ—Å–∫–∏–º —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∞–º –æ–ø—É—Ö–æ–ª–∏.

–û–¥–Ω–∞–∫–æ –±–µ–∑ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –ø—Ä–æ–∏–∑–≤–æ–¥–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ (–Ω–∞–ø—Ä–∏–º–µ—Ä, symmetry_worst) —Ç–æ—á–Ω–æ—Å—Ç—å –æ—Å—Ç–∞—ë—Ç—Å—è –Ω–∞ —É–º–µ—Ä–µ–Ω–Ω–æ–º —É—Ä–æ–≤–Ω–µ.

–≠—Ç–æ –ª–æ–≥–∏—á–Ω–æ: —Å–∏–º–º–µ—Ç—Ä–∏—è –æ–ø—É—Ö–æ–ª–∏ ‚Äî —Å–ª–æ–∂–Ω—ã–π –ø–∞—Ä–∞–º–µ—Ç—Ä, –∫–æ—Ç–æ—Ä—ã–π –Ω–µ –≤—Å–µ–≥–¥–∞ –Ω–∞–ø—Ä—è–º—É—é —Å–≤—è–∑–∞–Ω —Å —Ä–∞–∑–º–µ—Ä–∞–º–∏ –∏ –ø–ª–æ—â–∞–¥—å—é.

# –ó–∞–¥–∞–Ω–∏–µ 2

–ü—É—Å—Ç—å –∫–æ–ª–æ–Ω–∫–∞ —Å –¥–∏–∞–≥–Ω–æ–∑–æ–º –ø—Ä–∏–Ω–∏–º–∞–µ—Ç —Å–ª–µ–¥—É—é—â–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è: –∑–ª–æ–∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω–∞—è –æ–ø—É—Ö–æ–ª—å (M) ‚Äî 1, –∞ –¥–æ–±—Ä–æ–∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω–∞—è (B) ‚Äî 0. –ü–æ—Å—Ç—Ä–æ–π—Ç–µ –º–æ–¥–µ–ª—å (–∏–ª–∏ –Ω–µ—Å–∫–æ–ª—å–∫–æ –º–æ–¥–µ–ª–µ–π), –∫–æ—Ç–æ—Ä–∞—è –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–ª–∞ –±—ã –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –≤–æ–∑–Ω–∏–∫–Ω–æ–≤–µ–Ω–∏—è –∑–ª–æ–∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω–æ–π –æ–ø—É—Ö–æ–ª–∏:
- –æ—Ç —Å—Ä–µ–¥–Ω–µ–≥–æ —Ä–∞–¥–∏—É—Å–∞;
- —Å—Ä–µ–¥–Ω–µ–π –ø–ª–æ—â–∞–¥–∏;
- —Å—Ä–µ–¥–Ω–µ–π —Ç–µ–∫—Å—Ç—É—Ä—ã.

–ü–æ—Å—Ç—Ä–æ–π—Ç–µ –≥—Ä–∞—Ñ–∏–∫–∏. –°–æ–∑–¥–∞–π—Ç–µ –º–æ–¥–µ–ª—å, –∫–æ—Ç–æ—Ä–∞—è –±—ã –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–ª–∞ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –≤–æ–∑–Ω–∏–∫–Ω–æ–≤–µ–Ω–∏—è –∑–ª–æ–∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω–æ–π –æ–ø—É—Ö–æ–ª–∏ –æ—Ç –≤—Å–µ—Ö —Ç—Ä–µ—Ö –ø–µ—Ä–µ—á–∏—Å–ª–µ–Ω–Ω—ã—Ö —Ñ–∞–∫—Ç–æ—Ä–æ–≤.


–ü–µ—Ä–≤–∏—á–Ω—ã–π —Ä–∞—Å—á—ë—Ç –ø–æ —É–ø—Ä–æ—â—ë–Ω–Ω–æ–π —Ñ–æ—Ä–º—É–ª–µ

```{r}
library(MASS)

# –ó–∞–¥–∞–Ω–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
HR <- 2
p1 <- 0.5
p2 <- 0.5
d <- 0.8
Z <- qnorm(0.975)  # 95% –¥–æ–≤–µ—Ä–∏—Ç–µ–ª—å–Ω—ã–π –∏–Ω—Ç–µ—Ä–≤–∞–ª

# –†–∞—Å—á—ë—Ç
ln_HR <- log(HR)
n_per_group <- ((Z / 2 + Z)^2) * (ln_HR^2) * p1 * p2 * d
n_total <- n_per_group * 2

cat(sprintf("–†–∞–∑–º–µ—Ä –∫–∞–∂–¥–æ–π –≥—Ä—É–ø–ø—ã: %.0f\n", n_per_group))
cat(sprintf("–û–±—â–∏–π —Ä–∞–∑–º–µ—Ä –≤—ã–±–æ—Ä–∫–∏: %.0f\n", n_total))

```

–≠—Ç–æ—Ç —Ä–∞—Å—á–µ—Ç –Ω–µ —É—á–∏—Ç—ã–≤–∞–µ—Ç —Ç—Ä–µ–±—É–µ–º—É—é –º–æ—â–Ω–æ—Å—Ç—å —Ç–µ—Å—Ç–∞ (power), –ø–æ—ç—Ç–æ–º—É –ø—Ä–∏–≤–æ–¥–∏—Ç –∫ –∑–∞–Ω–∏–∂–µ–Ω–Ω–æ–º—É —Ä–∞–∑–º–µ—Ä—É –≤—ã–±–æ—Ä–∫–∏.


–ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ —Ä–∞–∑–º–µ—Ä–∞ –≤—ã–±–æ—Ä–∫–∏ –æ—Ç Hazard Ratio:

```{r}
library(ggplot2)

alpha <- 0.05
power <- 0.8
p <- 0.5
event_rate <- 0.8

# –§—É–Ω–∫—Ü–∏—è –¥–ª—è —Ä–∞—Å—á–µ—Ç–∞ —Ä–∞–∑–º–µ—Ä–∞ –≤—ã–±–æ—Ä–∫–∏
sample_size_cph <- function(alpha, power, p, event_rate, HR) {
  log_HR <- log(HR)
  n <- (qnorm(1 - alpha/2) + qnorm(power))^2 * (p*(1-p) + event_rate*(1-event_rate)) / log_HR^2
  return(n)
}

# –†–∞—Å—á—ë—Ç –¥–ª—è —Ä–∞–∑–Ω—ã—Ö HR
hr_values <- seq(1.1, 3.0, length.out = 50)
sample_sizes <- sapply(hr_values, function(HR) sample_size_cph(alpha, power, p, event_rate, HR))

data.frame(HR = hr_values, SampleSize = sample_sizes) %>%
  ggplot(aes(x = HR, y = SampleSize)) +
  geom_line() + geom_point() +
  labs(x = "Hazard Ratio", y = "–†–∞–∑–º–µ—Ä –≤—ã–±–æ—Ä–∫–∏", title = "–ó–∞–≤–∏—Å–∏–º–æ—Å—Ç—å —Ä–∞–∑–º–µ—Ä–∞ –≤—ã–±–æ—Ä–∫–∏ –æ—Ç HR") +
  theme_minimal()

```

–ü—Ä–∏ HR ‚Üí 1 –Ω–µ–æ–±—Ö–æ–¥–∏–º–∞—è –≤—ã–±–æ—Ä–∫–∞ —Å—Ç—Ä–µ–º–∏—Ç—Å—è –∫ –±–µ—Å–∫–æ–Ω–µ—á–Ω–æ—Å—Ç–∏.

–ü—Ä–∏ HR = 2‚Äì3 ‚Äî –≤—ã–±–æ—Ä–∫–∞ —É–º–µ–Ω—å—à–∞–µ—Ç—Å—è.



–ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ —Ä–∞–∑–º–µ—Ä–∞ –≤—ã–±–æ—Ä–∫–∏ –æ—Ç –º–æ—â–Ω–æ—Å—Ç–∏ —Ç–µ—Å—Ç–∞:

```{r}
powers <- seq(0.6, 0.99, length.out = 40)

sample_size_power <- function(log_HR, power, alpha, p, event_rate) {
  Z <- qnorm(1 - alpha/2) + qnorm(power)
  n <- (Z^2 * (p*(1-p) + event_rate*(1-event_rate))) / log_HR^2
  return(n)
}

log_HR <- log(2)

sample_sizes_power <- sapply(powers, function(power) sample_size_power(log_HR, power, alpha, p, event_rate))

data.frame(Power = powers, SampleSize = sample_sizes_power) %>%
  ggplot(aes(x = Power, y = SampleSize)) +
  geom_line(color = "green") + geom_point(color = "green") +
  labs(x = "–ú–æ—â–Ω–æ—Å—Ç—å —Ç–µ—Å—Ç–∞ (Power)", y = "–†–∞–∑–º–µ—Ä –≤—ã–±–æ—Ä–∫–∏", title = "–ó–∞–≤–∏—Å–∏–º–æ—Å—Ç—å —Ä–∞–∑–º–µ—Ä–∞ –≤—ã–±–æ—Ä–∫–∏ –æ—Ç –º–æ—â–Ω–æ—Å—Ç–∏ —Ç–µ—Å—Ç–∞") +
  theme_minimal()

```

–ß–µ–º –≤—ã—à–µ —Ç—Ä–µ–±—É–µ–º–∞—è –º–æ—â–Ω–æ—Å—Ç—å —Ç–µ—Å—Ç–∞, —Ç–µ–º –±–æ–ª—å—à–µ –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å –≤—ã–±–æ—Ä–∫–∞.


Grid Search: –ø–µ—Ä–µ–±–æ—Ä —Ä–∞–∑–ª–∏—á–Ω—ã—Ö —Å–æ—á–µ—Ç–∞–Ω–∏–π –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤:

```{r}
library(dplyr)

# –ü–µ—Ä–µ–±–æ—Ä –∑–Ω–∞—á–µ–Ω–∏–π HR, Power –∏ Event Rate
hr_values <- seq(1.1, 3.0, by = 0.2)
power_values <- c(0.8, 0.85, 0.9)
event_rates <- c(0.6, 0.7, 0.8, 0.9)

results <- expand.grid(HR = hr_values, Power = power_values, EventRate = event_rates) %>%
  mutate(SampleSize = ceiling(
    (qnorm(1 - alpha/2) + qnorm(Power))^2 * (p*(1-p) + EventRate*(1-EventRate)) / log(HR)^2 * 2
  ))

results <- results %>%
  mutate(AdjustedSampleSize = ceiling(SampleSize / EventRate)) %>%
  arrange(AdjustedSampleSize)

head(results, 10)

```


–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è —á–µ—Ä–µ–∑ nloptr:

```{r}
library(powerSurvEpi)
library(nloptr)

objective_function <- function(params) {
  hr <- params[1]
  power <- params[2]
  pC <- params[3]
  
  tryCatch({
    sample_size <- ssizeCT.default(
      power = power, k = 1, pE = pC * hr, pC = pC, RR = hr, alpha = 0.05
    )
    return(ceiling(sample_size))
  }, error = function(e) {
    return(Inf)
  })
}

# –ü–æ–∏—Å–∫ –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
result <- nloptr(
  x0 = c(1.5, 0.825, 0.75),
  eval_f = objective_function,
  lb = c(1.1, 0.8, 0.6),
  ub = c(3.1, 0.85, 0.9),
  opts = list(algorithm = "NLOPT_GN_CRS2_LM", maxeval = 100)
)

if (result$objective < Inf) {
  cat("–õ—É—á—à–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã (HR, Power, pC):", paste(round(result$solution, 3), collapse = ", "), "\n")
  cat("–ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä –≤—ã–±–æ—Ä–∫–∏:", result$objective, "\n")
} else {
  cat("–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –Ω–µ —É–¥–∞–ª–∞—Å—å.\n")
}
```

–†—É—á–Ω–æ–π –ø–µ—Ä–µ–±–æ—Ä –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –ø—Ä–µ–¥–ª–æ–∂–∏–ª:
HR = 2.9, Power = 0.80, Event Rate = 0.9 ‚Üí Adjusted Sample Size = 8

–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –Ω–∞—à–ª–∞:
HR = 3.1, Power = 0.83, Event Rate = 0.9 ‚Üí Adjusted Sample Size = 9

–†–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏ —Å–æ–≤–ø–∞–ª–∏, —á—Ç–æ –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–∞–µ—Ç –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ—Å—Ç—å –º–µ—Ç–æ–¥–∏–∫–∏.


–ò—Ç–æ–≥–∏:
–£–ø—Ä–æ—â—ë–Ω–Ω—ã–π —Ä–∞—Å—á–µ—Ç –Ω–µ–¥–æ—Å—Ç–æ–≤–µ—Ä–µ–Ω ‚Äî –æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ —É—á–∏—Ç—ã–≤–∞—Ç—å –º–æ—â–Ω–æ—Å—Ç—å —Ç–µ—Å—Ç–∞.
–ß–µ–º –≤—ã—à–µ HR –∏–ª–∏ event rate, —Ç–µ–º –º–µ–Ω—å—à–µ –Ω—É–∂–Ω–∞ –≤—ã–±–æ—Ä–∫–∞.
–°—Ç–∞–Ω–¥–∞—Ä—Ç—ã –∫–ª–∏–Ω–∏—á–µ—Å–∫–∏—Ö –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–π —Ç—Ä–µ–±—É—é—Ç –º–æ—â–Ω–æ—Å—Ç—å ‚â• 80% –¥–ª—è –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã—Ö –≤—ã–≤–æ–¥–æ–≤.




# –ó–∞–¥–∞–Ω–∏–µ 3

–†–∞—Å—Å—á–∏—Ç–∞–π—Ç–µ –≤—ã–±–æ—Ä–∫—É –¥–ª—è –≥–∏–ø–æ—Ç–µ–∑—ã equality –¥–ª—è —Å–ª–µ–¥—É—é—â–µ–≥–æ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è. –ú—ã —Ö–æ—Ç–∏–º —Å—Ä–∞–≤–Ω–∏—Ç—å –Ω–æ–≤—É—é —Ç–µ—Ä–∞–ø–∏—é –∏–Ω—Ñ–µ–∫—Ü–∏–∏, –ø—Ä–∏—Å–æ–µ–¥–∏–Ω—è—é—â–µ–π—Å—è –≤ –±–æ–ª—å–Ω–∏—á–Ω—ã—Ö —É—Å–ª–æ–≤–∏—è—Ö —É –ø–∞—Ü–∏–µ–Ω—Ç–æ–≤ —Å –æ–∂–æ–≥–∞–º–∏, —Å –∑–æ–ª–æ—Ç—ã–º —Å—Ç–∞–Ω–¥–∞—Ä—Ç–æ–º, –æ—Å–Ω–æ–≤—ã–≤–∞—è—Å—å –Ω–∞ –¥–∞–Ω–Ω—ã—Ö, –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º—ã—Ö —Å –ø–æ–º–æ—â—å—é —Ä–µ–≥—Ä–µ—Å—Å–∏–∏ –ö–æ–∫—Å–∞. –ü—É—Å—Ç—å –æ—Ç–Ω–æ—à–µ–Ω–∏–µ —Ä–∏—Å–∫–æ–≤ ¬´–∑–æ–ª–æ—Ç–æ–π —Å—Ç–∞–Ω–¥–∞—Ä—Ç / –Ω–æ–≤–∞—è —Ç–µ—Ä–∞–ø–∏—è¬ª, hazard ratio, HR = 2. –ú—ã –ø—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ–º, —á—Ç–æ 80% –ø–∞—Ü–∏–µ–Ω—Ç–æ–≤ (d = 0,8) –º–æ–≥—É—Ç —Å—Ç–æ–ª–∫–Ω—É—Ç—å—Å—è —Å —ç—Ç–∏–º –∑–∞–±–æ–ª–µ–≤–∞–Ω–∏–µ–º. –°–æ–æ—Ç–Ω–æ—à–µ–Ω–∏—è –≥—Ä—É–ø–ø —Ç–µ—Ä–∞–ø–∏–∏ —Ä–∞–≤–Ω—ã (p1 = p2 = 0,5).

```{r}
library(MASS)

# –î–∞–Ω–æ:
alpha <- 0.05     # —É—Ä–æ–≤–µ–Ω—å –∑–Ω–∞—á–∏–º–æ—Å—Ç–∏
power <- 0.8      # –º–æ—â–Ω–æ—Å—Ç—å —Ç–µ—Å—Ç–∞
HR <- 2           # Hazard Ratio
d <- 0.8          # –¥–æ–ª—è –ø–∞—Ü–∏–µ–Ω—Ç–æ–≤ —Å —Å–æ–±—ã—Ç–∏–µ–º
p1 <- 0.5         # –ø—Ä–æ–ø–æ—Ä—Ü–∏–∏ –≥—Ä—É–ø–ø
p2 <- 0.5

# –†–∞—Å—á—ë—Ç Z-–∑–Ω–∞—á–µ–Ω–∏–π
Z_alpha <- qnorm(1 - alpha / 2)    # –¥–ª—è –¥–≤—É—Å—Ç–æ—Ä–æ–Ω–Ω–µ–≥–æ —Ç–µ—Å—Ç–∞
Z_beta <- qnorm(power)

# –õ–æ–≥–∞—Ä–∏—Ñ–º Hazard Ratio
ln_HR <- log(HR)

# –†–∞—Å—á—ë—Ç –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ —Å–æ–±—ã—Ç–∏–π
events_needed <- ((Z_alpha + Z_beta)^2) / (ln_HR^2)

# –ü–µ—Ä–µ–≤–æ–¥ –≤ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–∞—Ü–∏–µ–Ω—Ç–æ–≤, —É—á–∏—Ç—ã–≤–∞—è –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å —Å–æ–±—ã—Ç–∏—è d
n_total <- events_needed / d

cat(sprintf("–ù–µ–æ–±—Ö–æ–¥–∏–º–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–æ–±—ã—Ç–∏–π: %.0f\n", ceiling(events_needed)))
cat(sprintf("–û–±—â–∏–π —Ä–∞–∑–º–µ—Ä –≤—ã–±–æ—Ä–∫–∏: %.0f –ø–∞—Ü–∏–µ–Ω—Ç–æ–≤\n", ceiling(n_total)))
cat(sprintf("–†–∞–∑–º–µ—Ä –∫–∞–∂–¥–æ–π –≥—Ä—É–ø–ø—ã: %.0f –ø–∞—Ü–∏–µ–Ω—Ç–æ–≤\n", ceiling(n_total / 2)))
```

–†–µ–∑—É–ª—å—Ç–∞—Ç—ã:
–ù–µ–æ–±—Ö–æ–¥–∏–º–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–æ–±—ã—Ç–∏–π ‚âà 17.
–û–±—â–∏–π —Ä–∞–∑–º–µ—Ä –≤—ã–±–æ—Ä–∫–∏ ‚âà 22 –ø–∞—Ü–∏–µ–Ω—Ç–∞.
–í –∫–∞–∂–¥–æ–π –≥—Ä—É–ø–ø–µ ‚âà 11 –ø–∞—Ü–∏–µ–Ω—Ç–∞.
–ü–æ–ª—É—á–µ–Ω–Ω–∞—è –≤—ã–±–æ—Ä–∫–∞ –∫–∞–∂–µ—Ç—Å—è –º–∞–ª–µ–Ω—å–∫–æ–π ‚Äî —ç—Ç–æ —Å–≤—è–∑–∞–Ω–æ —Å —Ç–µ–º, —á—Ç–æ –∑–∞–¥–∞–Ω–æ –æ—á–µ–Ω—å —Å–∏–ª—å–Ω–æ–µ –æ—Ç–ª–∏—á–∏–µ –º–µ–∂–¥—É –≥—Ä—É–ø–ø–∞–º–∏ (HR = 2).
–í —Ä–µ–∞–ª—å–Ω—ã—Ö –∫–ª–∏–Ω–∏—á–µ—Å–∫–∏—Ö –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è—Ö –æ–±—ã—á–Ω–æ —É—á–∏—Ç—ã–≤–∞—é—Ç:
- –ü–æ—Ç–µ—Ä–∏ –¥–∞–Ω–Ω—ã—Ö (drop-out),
- –û—à–∏–±–∫–∏ –∏–∑–º–µ—Ä–µ–Ω–∏–π,
- –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —Å—Ç—Ä–∞—Ç–∏—Ñ–∏–∫–∞—Ü–∏–∏.
–ü–æ—ç—Ç–æ–º—É –Ω–∞ –ø—Ä–∞–∫—Ç–∏–∫–µ –∏—Ç–æ–≥–æ–≤—ã–π —Ä–∞—Å—á–µ—Ç –º–æ–∂–µ—Ç –±—ã—Ç—å –∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω–æ —É–≤–µ–ª–∏—á–µ–Ω –Ω–∞ 10‚Äì20%.


–î–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è —Ç–µ—Ä–∞–ø–∏–∏ —Å Hazard Ratio = 2, –ø—Ä–∏ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ —Å–æ–±—ã—Ç–∏—è d = 0.8 –∏ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–∞—Ö —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è (Œ± = 0.05, –º–æ—â–Ω–æ—Å—Ç—å = 80%),
–Ω–µ–æ–±—Ö–æ–¥–∏–º–æ –≤–∫–ª—é—á–∏—Ç—å –ø—Ä–∏–º–µ—Ä–Ω–æ 22 –ø–∞—Ü–∏–µ–Ω—Ç–∞ (–ø–æ 11 –≤ –∫–∞–∂–¥—É—é –≥—Ä—É–ø–ø—É).