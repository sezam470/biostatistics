# –ó–∞–¥–∞–Ω–∏–µ 1

------------------------------------------------------------------------

–°–æ–∑–¥–∞—Ç—å —Ä–µ–≥—Ä–µ—Å—Å–∏–æ–Ω–Ω—É—é –º–æ–¥–µ–ª—å (–∏–ª–∏ –Ω–µ—Å–∫–æ–ª—å–∫–æ –º–æ–¥–µ–ª–µ–π), –∫–æ—Ç–æ—Ä–∞—è –æ–ø–∏—Å—ã–≤–∞–ª–∞ –±—ã —Å–≤—è–∑—å:

-   —Å—Ä–µ–¥–Ω–µ–≥–æ —Ä–∞–¥–∏—É—Å–∞ –æ–ø—É—Ö–æ–ª–∏ –∏ —Å—Ä–µ–¥–Ω–µ–π –ø–ª–æ—â–∞–¥–∏;

-   —Å—Ä–µ–¥–Ω–µ–≥–æ –ø–µ—Ä–∏–º–µ—Ç—Ä–∞;

-   —Å—Ä–µ–¥–Ω–µ–π —Å–∏–º–º–µ—Ç—Ä–∏—á–Ω–æ—Å—Ç–∏.

–ü–æ—Å—Ç—Ä–æ–π—Ç–µ –≥—Ä–∞—Ñ–∏–∫ (–∏–ª–∏ –≥—Ä–∞—Ñ–∏–∫–∏, –µ—Å–ª–∏ –º–æ–¥–µ–ª–µ–π –Ω–µ—Å–∫–æ–ª—å–∫–æ), –Ω–∞ –∫–æ—Ç–æ—Ä–æ–º –æ—Ç—Ä–∞–∑–∏—Ç–µ —Ä–µ–≥—Ä–µ—Å—Å–∏–æ–Ω–Ω—É—é –ø—Ä—è–º—É—é, –∏ –ø—Ä–æ–∫–æ–º–º–µ–Ω—Ç–∏—Ä—É–π—Ç–µ —Å–≤–æ–∏ –Ω–∞—Ö–æ–¥–∫–∏.


–ú–µ—Ç–æ–¥—ã:
- Univariate –∏ Multivariate —Ä–µ–≥—Ä–µ—Å—Å–∏–∏

- –ú–æ–¥–µ–ª–∏: –õ–∏–Ω–µ–π–Ω–∞—è —Ä–µ–≥—Ä–µ—Å—Å–∏—è, –ü–æ–ª–∏–Ω–æ–º–∏–∞–ª—å–Ω–∞—è —Ä–µ–≥—Ä–µ—Å—Å–∏—è (2-–π —Å—Ç–µ–ø–µ–Ω–∏), Random Forest, XGBoost

Univariate regression

```{r}
library(ggplot2)
library(dplyr)
library(caret)
library(Metrics)
library(randomForest)
library(xgboost)
library(broom)

df <- read.csv("wisconsin_breast_cancer.csv")
features <- c("area_mean", "perimeter_mean", "symmetry_mean")
target <- "radius_mean"

compute_metrics <- function(true, pred) {
  data.frame(
    MAE = mae(true, pred),
    MSE = mse(true, pred),
    RMSE = rmse(true, pred),
    R2 = R2(pred, true),
    stringsAsFactors = FALSE
  )
}

set.seed(42)

model_types <- list(
  "Linear" = function(train) lm(Y ~ X, data = train),
  "Polynomial" = function(train) lm(Y ~ poly(X, 2), data = train),
  "Random Forest" = function(train) randomForest(Y ~ X, data = train),
  "XGBoost" = function(train) {
    dtrain <- xgb.DMatrix(as.matrix(train$X), label = train$Y)
    xgb.train(list(objective = "reg:squarederror", max_depth = 3, eta = 0.1), dtrain, nrounds = 100)
  }
)

results_uni <- list()

par(mfrow = c(1, 3))

for (model_name in names(model_types)) {
  for (feature in features) {
    data_sub <- df[, c(feature, target)]
    names(data_sub) <- c("X", "Y")
    
    idx <- createDataPartition(data_sub$Y, p = 0.8, list = FALSE)
    train <- data_sub[idx, ]
    test <- data_sub[-idx, ]
    
    model <- model_types[[model_name]](train)
    
    pred <- if (model_name == "XGBoost") {
      predict(model, xgb.DMatrix(as.matrix(test$X)))
    } else {
      predict(model, newdata = test)
    }
    
    metrics <- compute_metrics(test$Y, pred)
    metrics$Model <- model_name
    metrics$Feature <- feature
    results_uni[[length(results_uni) + 1]] <- metrics
    
    plot(test$X, test$Y, main = paste(feature, "‚Üí", target), pch = 16, col = rgb(0,0,0,0.4),
         xlab = feature, ylab = target)
    points(test$X, pred, col = "red", pch = 16)
    legend("topleft", legend = c("Actual", "Predicted"), col = c("black", "red"), pch = 16)
  }
}

df_uni <- do.call(rbind, results_uni) %>% 
  arrange(Feature, desc(R2)) %>%
  mutate(across(where(is.numeric), round, 4))

print(df_uni)
```

area_mean –∏ perimeter_mean –ø—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞—é—Ç radius_mean —Å –æ—á–µ–Ω—å –≤—ã—Å–æ–∫–æ–π —Ç–æ—á–Ω–æ—Å—Ç—å—é (R¬≤ > 0.98).

symmetry_mean —Å–ª–∞–±–æ –∫–æ—Ä—Ä–µ–ª–∏—Ä—É–µ—Ç —Å —Ü–µ–ª–µ–≤—ã–º –ø—Ä–∏–∑–Ω–∞–∫–æ–º (–Ω–∏–∑–∫–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è R¬≤).



–ü—Ä–æ–≤–µ—Ä–∏–º Multivariate regression:

```{r}
set.seed(42)

X <- df[, features]
y <- df[, target]

idx <- createDataPartition(y, p = 0.8, list = FALSE)
X_train <- X[idx, ]
X_test  <- X[-idx, ]
y_train <- y[idx]
y_test  <- y[-idx]

model_types_multi <- list(
  "Linear" = function() lm(y_train ~ ., data = X_train),
  "Polynomial" = function() lm(y_train ~ poly(area_mean, 2) + poly(perimeter_mean, 2) + poly(symmetry_mean, 2), data = X_train),
  "Random Forest" = function() randomForest(y_train ~ ., data = X_train),
  "XGBoost" = function() {
    dtrain <- xgb.DMatrix(as.matrix(X_train), label = y_train)
    xgb.train(list(objective = "reg:squarederror", max_depth = 3, eta = 0.1), dtrain, nrounds = 100)
  }
)

results_multi <- list()

for (model_name in names(model_types_multi)) {
  model <- model_types_multi[[model_name]]()
  
  pred <- if (model_name == "XGBoost") {
    predict(model, xgb.DMatrix(as.matrix(X_test)))
  } else {
    predict(model, newdata = X_test)
  }
  
  metrics <- compute_metrics(y_test, pred)
  metrics$Model <- model_name
  results_multi[[length(results_multi) + 1]] <- metrics
  
  print(
    ggplot(data.frame(y_test, pred), aes(x = y_test, y = pred)) +
      geom_point(alpha = 0.5) +
      geom_abline(slope = 1, intercept = 0, color = "red") +
      ggtitle(paste(model_name, " ‚Äî All features ‚Üí", target)) +
      xlab("Actual") + ylab("Predicted") +
      theme_minimal()
  )
}

df_multi <- do.call(rbind, results_multi) %>%
  mutate(across(where(is.numeric), round, 4)) %>%
  arrange(desc(R2))

print(df_multi)

```

–ö–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–∞–µ—Ç –≤—ã—Å–æ–∫—É—é –ª–∏–Ω–µ–π–Ω—É—é –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç—å radius_mean –æ—Ç area_mean –∏ perimeter_mean.

–ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ —Å–ª–æ–∂–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π —Ç–∏–ø–∞ Random Forest –∏ XGBoost –Ω–µ –¥–∞—ë—Ç —Å—É—â–µ—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ –ø—Ä–∏—Ä–æ—Å—Ç–∞ –∫–∞—á–µ—Å—Ç–≤–∞ –ø–æ —Å—Ä–∞–≤–Ω–µ–Ω–∏—é —Å –ª–∏–Ω–µ–π–Ω—ã–º–∏ –º–æ–¥–µ–ª—è–º–∏.

```{r}
library(ggplot2)
library(Metrics)

# –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö
df <- read.csv("wisconsin_breast_cancer.csv")

# –§—É–Ω–∫—Ü–∏—è –¥–ª—è —Ä–∞—Å—á—ë—Ç–∞, –º–µ—Ç—Ä–∏–∫ –∏ –≥—Ä–∞—Ñ–∏–∫–∞
evaluate_estimation <- function(true_values, predicted_values, true_label, pred_label) {
  cat(sprintf("\n–†–∞—Å—á—ë—Ç %s —á–µ—Ä–µ–∑ %s:\n", true_label, pred_label))
  cat(sprintf("MAE:  %.4f\n", mae(true_values, predicted_values)))
  cat(sprintf("MSE:  %.4f\n", mse(true_values, predicted_values)))
  cat(sprintf("RMSE: %.4f\n", rmse(true_values, predicted_values)))
  cat(sprintf("R¬≤:   %.4f\n", R2(predicted_values, true_values)))
  
  ggplot(data.frame(True = true_values, Predicted = predicted_values), aes(x = True, y = Predicted)) +
    geom_point(alpha = 0.6) +
    geom_abline(slope = 1, intercept = 0, color = "red", linetype = "dashed") +
    labs(
      x = paste("–§–∞–∫—Ç–∏—á–µ—Å–∫–∏–π", true_label),
      y = paste("–†–∞—Å—Å—á–∏—Ç–∞–Ω–Ω—ã–π", pred_label),
      title = paste("–°—Ä–∞–≤–Ω–µ–Ω–∏–µ:", true_label, "vs", pred_label)
    ) +
    theme_minimal() +
    theme(plot.title = element_text(hjust = 0.5))
}

# –û—Ü–µ–Ω–∫–∞ radius_mean —á–µ—Ä–µ–∑ area_mean
df$radius_estimated <- sqrt(df$area_mean / pi)
p1 <- evaluate_estimation(df$radius_mean, df$radius_estimated, "radius_mean", "radius_estimated")

# –û—Ü–µ–Ω–∫–∞ perimeter_mean —á–µ—Ä–µ–∑ radius_mean
df$perimeter_estimated <- 2 * pi * df$radius_mean
p2 <- evaluate_estimation(df$perimeter_mean, df$perimeter_estimated, "perimeter_mean", "perimeter_estimated")

# –í—ã–≤–æ–¥ –≥—Ä–∞—Ñ–∏–∫–æ–≤
p1
p2

```

r\^2 –±–ª–∏–∑–æ–∫ –∫ –µ–¥–∏–Ω–∏—Ü–µ


–ú—ã —É—Å—Ç–∞–Ω–æ–≤–∏–ª–∏, —á—Ç–æ —Ç–∞–∫–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –∫–∞–∫ area_mean, perimeter_mean –∏ radius_mean –º–æ–∂–Ω–æ –ª–µ–≥–∫–æ –≤—ã—á–∏—Å–ª—è—Ç—å –¥—Ä—É–≥ —á–µ—Ä–µ–∑ –¥—Ä—É–≥–∞, –±–ª–∞–≥–æ–¥–∞—Ä—è –∏—Ö —Ç–µ—Å–Ω–æ–π —Ñ–∏–∑–∏–∫–æ-–º–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–æ–π —Å–≤—è–∑–∏.

–û–¥–Ω–∞–∫–æ –≤ –¥–∞—Ç–∞—Å–µ—Ç–µ —Ç–∞–∫–∂–µ –ø—Ä–∏—Å—É—Ç—Å—Ç–≤—É–µ—Ç –ø—Ä–∏–∑–Ω–∞–∫ symmetry_mean, –∫–æ—Ç–æ—Ä—ã–π –¥–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä—É–µ—Ç —Å–ª–∞–±—É—é –ª–∏–Ω–µ–π–Ω—É—é –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç—å —Å –æ—Å—Ç–∞–ª—å–Ω—ã–º–∏ –ø—Ä–∏–∑–Ω–∞–∫–∞–º–∏.
–° –∏—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å—Å–∫–æ–π —Ç–æ—á–∫–∏ –∑—Ä–µ–Ω–∏—è –∏–Ω—Ç–µ—Ä–µ—Å–Ω–æ –ø—Ä–æ–≤–µ—Ä–∏—Ç—å, –≤–æ–∑–º–æ–∂–Ω–æ –ª–∏ –µ–≥–æ –Ω–∞–¥—ë–∂–Ω–æ –ø—Ä–µ–¥—Å–∫–∞–∑–∞—Ç—å.

–ü–æ—Å–∫–æ–ª—å–∫—É –∏–Ω–¥–∏–≤–∏–¥—É–∞–ª—å–Ω–∞—è –∫–æ—Ä—Ä–µ–ª—è—Ü–∏—è symmetry_mean —Å –æ—Å—Ç–∞–ª—å–Ω—ã–º–∏ –ø—Ä–∏–∑–Ω–∞–∫–∞–º–∏ –Ω–∏–∑–∫–∞—è, –ø–µ—Ä–µ–π–¥–µ–º —Å—Ä–∞–∑—É –∫ –º—É–ª—å—Ç–∏—Ñ–∞–∫—Ç–æ—Ä–Ω–æ–º—É –º–æ–¥–µ–ª–∏—Ä–æ–≤–∞–Ω–∏—é (Multivariate Regression).

```{r}
library(ggplot2)
library(caret)
library(randomForest)
library(xgboost)
library(Metrics)

# –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö
df <- read.csv("wisconsin_breast_cancer.csv")
features <- c("area_mean", "perimeter_mean", "radius_mean")
target <- "symmetry_mean"

# –î–µ–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö
set.seed(42)
train_idx <- createDataPartition(df[[target]], p = 0.8, list = FALSE)
X_train <- df[train_idx, features]
X_test  <- df[-train_idx, features]
y_train <- df[train_idx, target]
y_test  <- df[-train_idx, target]

# –§—É–Ω–∫—Ü–∏—è –º–µ—Ç—Ä–∏–∫
compute_metrics <- function(true, pred) {
  data.frame(
    MAE = mae(true, pred),
    MSE = mse(true, pred),
    RMSE = rmse(true, pred),
    R2 = R2(pred, true)
  )
}

# –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π
models <- list(
  "Linear Regression" = function() lm(y_train ~ ., data = X_train),
  "Polynomial Regression" = function() lm(y_train ~ poly(area_mean, 2) + poly(perimeter_mean, 2) + poly(radius_mean, 2), data = X_train),
  "Random Forest" = function() randomForest(y_train ~ ., data = X_train),
  "XGBoost" = function() {
    dtrain <- xgb.DMatrix(data = as.matrix(X_train), label = y_train)
    xgb.train(list(objective = "reg:squarederror", max_depth = 3, eta = 0.1), dtrain, nrounds = 100)
  }
)

# –û–±—É—á–µ–Ω–∏–µ –∏ –æ—Ü–µ–Ω–∫–∞
results <- list()

for (name in names(models)) {
  model <- models[[name]]()
  preds <- if (name == "XGBoost") predict(model, xgb.DMatrix(as.matrix(X_test))) else predict(model, newdata = X_test)
  
  metrics <- compute_metrics(y_test, preds)
  metrics$Model <- name
  results[[length(results) + 1]] <- metrics
  
  print(ggplot(data.frame(Actual = y_test, Predicted = preds), aes(x = Actual, y = Predicted)) +
    geom_point(alpha = 0.6) +
    geom_abline(slope = 1, intercept = 0, color = "red", linetype = "dashed") +
    labs(title = paste(name, " ‚Äî", target), x = "–§–∞–∫—Ç–∏—á–µ—Å–∫–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ", y = "–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω–æ–µ") +
    theme_minimal())
}

# –ò—Ç–æ–≥–æ–≤–∞—è —Ç–∞–±–ª–∏—Ü–∞
results_df <- do.call(rbind, results) %>% 
  mutate(across(where(is.numeric), round, 4)) %>%
  arrange(desc(R2))

cat("\nüìä –ò—Ç–æ–≥–æ–≤—ã–µ –º–µ—Ç—Ä–∏–∫–∏:\n")
print(results_df)

```

–ü–æ–∫–∞–∑–∞—Ç–µ–ª—å R¬≤ –¥–ª—è Polynomial Regression —Å–æ—Å—Ç–∞–≤–∏–ª ~0.4013 ‚Äî –ª—É—á—à–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç —Å—Ä–µ–¥–∏ –ø—Ä–æ—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π.

–≠—Ç–æ –æ–∑–Ω–∞—á–∞–µ—Ç, —á—Ç–æ ~40% –¥–∏—Å–ø–µ—Ä—Å–∏–∏ –ø—Ä–∏–∑–Ω–∞–∫–∞ symmetry_mean –æ–±—ä—è—Å–Ω—è–µ—Ç—Å—è –Ω–∞—à–µ–π –º–æ–¥–µ–ª—å—é ‚Äî –¥–ª—è –º–µ–¥–∏—Ü–∏–Ω—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö —Ç–∞–∫–æ–π —É—Ä–æ–≤–µ–Ω—å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è —Å—á–∏—Ç–∞–µ—Ç—Å—è —É–º–µ—Ä–µ–Ω–Ω—ã–º.

–õ–∏–Ω–µ–π–Ω—ã–µ –∏ –ª–µ—Å–Ω—ã–µ –º–æ–¥–µ–ª–∏ —Å–ø—Ä–∞–≤–∏–ª–∏—Å—å –∑–∞–º–µ—Ç–Ω–æ —Ö—É–∂–µ.



–î–æ–±–∞–≤–ª–µ–Ω–∏–µ –≤—Å–µ—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –≤ –º–æ–¥–µ–ª—å.
–ß—Ç–æ–±—ã –ø–æ–ø—ã—Ç–∞—Ç—å—Å—è —É–ª—É—á—à–∏—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç, –º—ã —Ä–∞—Å—à–∏—Ä—è–µ–º –≤—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ, –≤–∫–ª—é—á–∞—è –≤—Å–µ –≤–æ–∑–º–æ–∂–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ (–∑–∞ –∏—Å–∫–ª—é—á–µ–Ω–∏–µ–º –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä–æ–≤ –∏ —Ü–µ–ª–µ–≤–æ–≥–æ –ø—Ä–∏–∑–Ω–∞–∫–∞).

```{r}
library(caret)
library(randomForest)
library(xgboost)
library(Metrics)
library(ggplot2)

df <- read.csv("wisconsin_breast_cancer.csv")
df <- df[, colSums(is.na(df)) == 0]

target <- "symmetry_mean"
X <- df[, setdiff(names(df), c("diagnosis", "id", target))]
y <- df[, target]

set.seed(42)
trainIndex <- createDataPartition(y, p = .8, list = FALSE)
X_train <- X[trainIndex, ]
X_test  <- X[-trainIndex, ]
y_train <- y[trainIndex]
y_test  <- y[-trainIndex]

compute_metrics <- function(true, pred) {
  data.frame(
    MAE = mae(true, pred),
    MSE = mse(true, pred),
    RMSE = rmse(true, pred),
    R2 = R2(pred, true)
  )
}

model_defs <- list(
  "Linear Regression" = function() lm(y_train ~ ., data = X_train),
  "Polynomial Regression" = function() lm(y_train ~ poly(area_mean, 2) + poly(perimeter_mean, 2) + poly(radius_mean, 2), data = X_train),
  "Random Forest" = function() randomForest(y_train ~ ., data = X_train),
  "XGBoost" = function() {
    dtrain <- xgb.DMatrix(data = as.matrix(X_train), label = y_train)
    param <- list(objective = "reg:squarederror", max_depth = 3, eta = 0.1)
    model <- xgb.train(param, dtrain, nrounds = 100)
    model
  }
)

saved_models <- list()
results <- list()

for (model_name in names(model_defs)) {
  print(paste("\n======", model_name, "====="))
  
  model_creator <- model_defs[[model_name]]
  model <- model_creator()
  
  if (model_name == "XGBoost") {
    dtest <- xgb.DMatrix(data = as.matrix(X_test))
    pred <- predict(model, dtest)
  } else {
    pred <- predict(model, newdata = X_test)
  }
  
  saved_models[[model_name]] <- model
  
  metrics <- compute_metrics(y_test, pred)
  metrics$Model <- model_name
  results[[length(results) + 1]] <- metrics
  
  print(ggplot(data.frame(y_test, pred), aes(x = y_test, y = pred)) +
    geom_point(alpha = 0.6) +
    geom_abline(slope = 1, intercept = 0, col = "red", linetype = "dashed") +
    ggtitle(paste(model_name, " ‚Äî All Features ‚Üí", target)) +
    xlab("Actual") + ylab("Predicted") +
    theme_minimal() +
    theme(plot.title = element_text(hjust = 0.5)))
}

results_df <- do.call(rbind, results)
results_df$Model <- as.character(results_df$Model)  # Ensure Model is character
results_df <- results_df[order(-results_df$R2), ]  # Sort by R2 descending

numeric_cols <- sapply(results_df, is.numeric)
results_df[numeric_cols] <- round(results_df[numeric_cols], 4)

cat("\n –ú–µ—Ç—Ä–∏–∫–∏ –í–∞—Ä–∏–∞–Ω—Ç–∞ 2:\n")
print(results_df)

```

–ü—Ä–∏ –¥–æ–±–∞–≤–ª–µ–Ω–∏–∏ –≤—Å–µ—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –∫–∞—á–µ—Å—Ç–≤–æ –º–æ–¥–µ–ª–µ–π —Å—É—â–µ—Å—Ç–≤–µ–Ω–Ω–æ —É–ª—É—á—à–∏–ª–æ—Å—å.

–û–¥–Ω–∞–∫–æ, –¥–∞–ª—å–Ω–µ–π—à–∏–π –∞–Ω–∞–ª–∏–∑ –≤–∞–∂–Ω–æ—Å—Ç–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –ø–æ–∫–∞–∑–∞–ª, —á—Ç–æ –Ω–∞ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ —Å–∏–ª—å–Ω–µ–µ –≤—Å–µ–≥–æ –≤–ª–∏—è–µ—Ç symmetry_worst.

```{r}
xgb_importance <- xgb.importance(model = saved_models[["XGBoost"]])

print(xgb_importance)

xgb.plot.importance(importance_matrix = xgb_importance, 
                    top_n = 10, 
                    main = "Top 10 Most Important Features for XGBoost")

```

–ß—Ç–æ–±—ã –∏—Å–∫–ª—é—á–∏—Ç—å —ç—Ñ—Ñ–µ–∫—Ç "–ø–æ–¥—Å–∫–∞–∑–∫–∏", –º—ã —É–¥–∞–ª—è–µ–º symmetry_worst –∏ –ø–µ—Ä–µ–æ–±—É—á–∞–µ–º –º–æ–¥–µ–ª–∏.

–†–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ–∂–∏–¥–∞–µ–º–æ —Å–Ω–∏–∑–∏–ª–∏—Å—å, –æ–¥–Ω–∞–∫–æ –º–æ–¥–µ–ª–∏ –≤—Å—ë –µ—â—ë –ø–æ–∫–∞–∑—ã–≤–∞—é—Ç –Ω–µ–∫–æ—Ç–æ—Ä–æ–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞—Ç–µ–ª—å–Ω–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ.

```{r}
library(caret)
library(randomForest)
library(xgboost)
library(Metrics)
library(ggplot2)

df <- read.csv("wisconsin_breast_cancer.csv")
df <- df[, colSums(is.na(df)) == 0]

target <- "symmetry_mean"
X <- df[, setdiff(names(df), c("diagnosis", "id", "symmetry_worst", target))]
y <- df[, target]

set.seed(42)
trainIndex <- createDataPartition(y, p = .8, list = FALSE)
X_train <- X[trainIndex, ]
X_test  <- X[-trainIndex, ]
y_train <- y[trainIndex]
y_test  <- y[-trainIndex]

compute_metrics <- function(true, pred) {
  data.frame(
    MAE = mae(true, pred),
    MSE = mse(true, pred),
    RMSE = rmse(true, pred),
    R2 = R2(pred, true)
  )
}

model_defs <- list(
  "Linear Regression" = function() lm(y_train ~ ., data = X_train),
  "Polynomial Regression" = function() lm(y_train ~ poly(area_mean, 2) + poly(perimeter_mean, 2) + poly(radius_mean, 2), data = X_train),
  "Random Forest" = function() randomForest(y_train ~ ., data = X_train),
  "XGBoost" = function() {
    dtrain <- xgb.DMatrix(data = as.matrix(X_train), label = y_train)
    param <- list(objective = "reg:squarederror", max_depth = 3, eta = 0.1)
    model <- xgb.train(param, dtrain, nrounds = 100)
    model
  }
)

saved_models <- list()
results <- list()

for (model_name in names(model_defs)) {
  print(paste("\n======", model_name, "====="))

  model_creator <- model_defs[[model_name]]
  model <- model_creator()
  
  if (model_name == "XGBoost") {
    dtest <- xgb.DMatrix(data = as.matrix(X_test))
    pred <- predict(model, dtest)
  } else {
    pred <- predict(model, newdata = X_test)
  }
  
  saved_models[[model_name]] <- model
  metrics <- compute_metrics(y_test, pred)
  metrics$Model <- model_name
  results[[length(results) + 1]] <- metrics
  
  print(ggplot(data.frame(y_test, pred), aes(x = y_test, y = pred)) +
    geom_point(alpha = 0.6) +
    geom_abline(slope = 1, intercept = 0, col = "red", linetype = "dashed") +
    ggtitle(paste(model_name, " ‚Äî All Features ‚Üí", target)) +
    xlab("Actual") + ylab("Predicted") +
    theme_minimal() +
    theme(plot.title = element_text(hjust = 0.5)))
}

results_df <- do.call(rbind, results)
results_df$Model <- as.character(results_df$Model)  # Ensure Model is character
results_df <- results_df[order(-results_df$R2), ]  # Sort by R2 descending

numeric_cols <- sapply(results_df, is.numeric)
results_df[numeric_cols] <- round(results_df[numeric_cols], 4)

cat("\n –ú–µ—Ç—Ä–∏–∫–∏ –í–∞—Ä–∏–∞–Ω—Ç–∞ 2:\n")
print(results_df)
```

–ó–Ω–∞—á–µ–Ω–∏–µ symmetry_mean –º–æ–∂–Ω–æ —á–∞—Å—Ç–∏—á–Ω–æ –ø—Ä–µ–¥—Å–∫–∞–∑–∞—Ç—å –ø–æ –±–∞–∑–æ–≤—ã–º –≥–µ–æ–º–µ—Ç—Ä–∏—á–µ—Å–∫–∏–º —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∞–º –æ–ø—É—Ö–æ–ª–∏.

–û–¥–Ω–∞–∫–æ –±–µ–∑ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –ø—Ä–æ–∏–∑–≤–æ–¥–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ (–Ω–∞–ø—Ä–∏–º–µ—Ä, symmetry_worst) —Ç–æ—á–Ω–æ—Å—Ç—å –æ—Å—Ç–∞—ë—Ç—Å—è –Ω–∞ —É–º–µ—Ä–µ–Ω–Ω–æ–º —É—Ä–æ–≤–Ω–µ.

–≠—Ç–æ –ª–æ–≥–∏—á–Ω–æ: —Å–∏–º–º–µ—Ç—Ä–∏—è –æ–ø—É—Ö–æ–ª–∏ ‚Äî —Å–ª–æ–∂–Ω—ã–π –ø–∞—Ä–∞–º–µ—Ç—Ä, –∫–æ—Ç–æ—Ä—ã–π –Ω–µ –≤—Å–µ–≥–¥–∞ –Ω–∞–ø—Ä—è–º—É—é —Å–≤—è–∑–∞–Ω —Å —Ä–∞–∑–º–µ—Ä–∞–º–∏ –∏ –ø–ª–æ—â–∞–¥—å—é.

# –ó–∞–¥–∞–Ω–∏–µ 2

–ü—É—Å—Ç—å –∫–æ–ª–æ–Ω–∫–∞ —Å –¥–∏–∞–≥–Ω–æ–∑–æ–º –ø—Ä–∏–Ω–∏–º–∞–µ—Ç —Å–ª–µ–¥—É—é—â–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è: –∑–ª–æ–∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω–∞—è –æ–ø—É—Ö–æ–ª—å (M) ‚Äî 1, –∞ –¥–æ–±—Ä–æ–∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω–∞—è (B) ‚Äî 0. –ü–æ—Å—Ç—Ä–æ–π—Ç–µ –º–æ–¥–µ–ª—å (–∏–ª–∏ –Ω–µ—Å–∫–æ–ª—å–∫–æ –º–æ–¥–µ–ª–µ–π), –∫–æ—Ç–æ—Ä–∞—è –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–ª–∞ –±—ã –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –≤–æ–∑–Ω–∏–∫–Ω–æ–≤–µ–Ω–∏—è –∑–ª–æ–∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω–æ–π –æ–ø—É—Ö–æ–ª–∏: –æ—Ç —Å—Ä–µ–¥–Ω–µ–≥–æ —Ä–∞–¥–∏—É—Å–∞; —Å—Ä–µ–¥–Ω–µ–π –ø–ª–æ—â–∞–¥–∏; —Å—Ä–µ–¥–Ω–µ–π —Ç–µ–∫—Å—Ç—É—Ä—ã. –ü–æ—Å—Ç—Ä–æ–π—Ç–µ –≥—Ä–∞—Ñ–∏–∫–∏. –°–æ–∑–¥–∞–π—Ç–µ –º–æ–¥–µ–ª—å, –∫–æ—Ç–æ—Ä–∞—è –±—ã –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–ª–∞ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –≤–æ–∑–Ω–∏–∫–Ω–æ–≤–µ–Ω–∏—è –∑–ª–æ–∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω–æ–π –æ–ø—É—Ö–æ–ª–∏ –æ—Ç –≤—Å–µ—Ö —Ç—Ä–µ—Ö –ø–µ—Ä–µ—á–∏—Å–ª–µ–Ω–Ω—ã—Ö —Ñ–∞–∫—Ç–æ—Ä–æ–≤.

–ó–¥–µ—Å—å –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –ø—Ä–∏–∑–Ω–∞–∫–∞ —Å—Ç—Ä–æ–∏—Ç—Å—è –ª–æ–≥–∏—Å—Ç–∏—á–µ—Å–∫–∞—è —Ä–µ–≥—Ä–µ—Å—Å–∏—è. –û—Ü–µ–Ω–∏–≤–∞–µ—Ç—Å—è –∫–∞—á–µ—Å—Ç–≤–æ –ø–æ –º–µ—Ç—Ä–∏–∫–∞–º AUC –∏ Accuracy.

–°—Ç—Ä–æ–∏—Ç—Å—è –≥—Ä–∞—Ñ–∏–∫,–∫–∞–∫ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –∑–ª–æ–∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç–∏ –∑–∞–≤–∏—Å–∏—Ç –æ—Ç –∑–Ω–∞—á–µ–Ω–∏—è –ø—Ä–∏–∑–Ω–∞–∫–∞.

------------------------------------------------------------------------

–î–∞–ª–µ–µ –º—ã —Å—Ç—Ä–æ–∏–º –º–æ–¥–µ–ª—å –ø–æ –≤—Å–µ–º —Ç—Ä—ë–º –ø—Ä–∏–∑–Ω–∞–∫–∞–º –í—ã—á–∏—Å–ª—è—é—Ç—Å—è AUC, Accuracy, –∏ Classification Report.

–°—Ç—Ä–æ—è—Ç—Å—è: ROC-–∫—Ä–∏–≤–∞—è (–æ—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ –º–æ–¥–µ–ª–∏), –ú–∞—Ç—Ä–∏—Ü–∞ –æ—à–∏–±–æ–∫ (confusion matrix).

```{r}
library(caret)
library(pROC)
library(ggplot2)
library(reshape2)
library(e1071)

df <- read.csv("wisconsin_breast_cancer.csv")

df$diagnosis_binary <- ifelse(df$diagnosis == "M", 1, 0)

features <- c("radius_mean", "area_mean", "texture_mean")
X_all <- df[, features]
y <- df$diagnosis_binary

set.seed(42)
trainIndex <- createDataPartition(y, p = 0.8, list = FALSE)
X_train_all <- X_all[trainIndex, ]
X_test_all <- X_all[-trainIndex, ]
y_train <- y[trainIndex]
y_test <- y[-trainIndex]

for (feature in features) {
  X <- df[, feature, drop = FALSE]
  trainIndex_f <- createDataPartition(y, p = 0.8, list = FALSE)
  X_train <- X[trainIndex_f, , drop = FALSE]
  X_test <- X[-trainIndex_f, , drop = FALSE]
  y_train_f <- y[trainIndex_f]
  y_test_f <- y[-trainIndex_f]
  
  model <- glm(y_train_f ~ ., data = data.frame(X_train, y_train_f), family = binomial())
  
  probs <- predict(model, newdata = X_test, type = "response")
  
  roc_curve <- roc(y_test_f, probs)
  auc <- auc(roc_curve)  # AUC –∏–∑ pROC
  pred <- ifelse(probs > 0.5, 1, 0)
  acc <- mean(pred == y_test_f)
  
  cat("\n–ú–æ–¥–µ–ª—å –ø–æ –ø—Ä–∏–∑–Ω–∞–∫—É:", feature, "\n")
  cat("AUC:", auc, "| Accuracy:", acc, "\n")
  
  print(ggplot(data.frame(X_test, probs, y_test_f), aes(x = X_test[[feature]], y = probs,     color = as.factor(y_test_f))) +
    geom_point(alpha = 0.7) +
    labs(title = paste("–í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –∑–ª–æ–∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç–∏ –æ—Ç", feature), 
         x = feature, y = "P(Malignant)") +
    theme_minimal() +
    scale_color_manual(values = c("blue", "red")))
}

plot(roc_curve_all, main = "ROC-–∫—Ä–∏–≤–∞—è –¥–ª—è –º–æ–¥–µ–ª–∏ –ø–æ –≤—Å–µ–º –ø—Ä–∏–∑–Ω–∞–∫–∞–º", 
     col = "red", lwd = 2)
legend("bottomright", legend = paste("AUC =", round(auc_all, 3)), 
       col = "red", lwd = 2)

model_all <- glm(y_train ~ ., data = data.frame(X_train_all, y_train), family = binomial())
probs_all <- predict(model_all, newdata = X_test_all, type = "response")

roc_curve_all <- roc(y_test, probs_all)
auc_all <- auc(roc_curve_all)
pred_all <- ifelse(probs_all > 0.5, 1, 0)
acc_all <- mean(pred_all == y_test)

cat("\n–ú–æ–¥–µ–ª—å –ø–æ –≤—Å–µ–º —Ç—Ä—ë–º –ø—Ä–∏–∑–Ω–∞–∫–∞–º:\n")
cat("AUC:", auc_all, "| Accuracy:", acc_all, "\n")

conf_matrix <- table(Predicted = pred_all, Actual = y_test)

conf_matrix_df <- as.data.frame(conf_matrix)
names(conf_matrix_df) <- c("Predicted", "Actual", "Count")

ggplot(conf_matrix_df, aes(x = Predicted, y = Actual, fill = Count)) +
  geom_tile(color = "white") +
  geom_text(aes(label = Count), color = "white", size = 5) +
  labs(title = "–ú–∞—Ç—Ä–∏—Ü–∞ –æ—à–∏–±–æ–∫", 
       x = "–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–π –∫–ª–∞—Å—Å", 
       y = "–ò—Å—Ç–∏–Ω–Ω—ã–π –∫–ª–∞—Å—Å") +
  theme_minimal() +
  scale_fill_gradient(low = "lightblue", high = "darkblue") +
  coord_fixed()

```

area_mean –∏ radius_mean –ø–æ–∫–∞–∑–∞–ª–∏ –ø–æ—á—Ç–∏ –∏–¥–µ–Ω—Ç–∏—á–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å –æ—á–µ–Ω—å –≤—ã—Å–æ–∫–æ–π AUC (\~0.91 - 0.94) –∏ —Ç–æ—á–Ω–æ—Å—Ç—å—é \~85 - 88%.

texture_mean –∑–∞–º–µ—Ç–Ω–æ —É—Å—Ç—É–ø–∞–µ—Ç ‚Äî AUC –≤—Å–µ–≥–æ 0.75 –∏ —Ç–æ—á–Ω–æ—Å—Ç—å –Ω–∏–∂–µ 65%, —Ç–æ –µ—Å—Ç—å —ç—Ç–æ—Ç –ø—Ä–∏–∑–Ω–∞–∫ —Å–∞–º –ø–æ —Å–µ–±–µ —Å–ª–∞–±–æ –∏–Ω—Ñ–æ—Ä–º–∞—Ç–∏–≤–µ–Ω.

–ú–æ–¥–µ–ª—å –Ω–∞ —Ç—Ä—ë—Ö –ø—Ä–∏–∑–Ω–∞–∫–∞—Ö –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω–æ: AUC: 0.9431, Accuracy: 0.876 (–ø—Ä–∏–º–µ—Ä–Ω–æ –∫–∞–∫ —É radius_mean).

–ö–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –º–æ–¥–µ–ª—å –¥–∞—ë—Ç –ø—Ä–∏–º–µ—Ä–Ω–æ —Ç–µ –∂–µ –ø–æ–∫–∞–∑–∞—Ç–µ–ª–∏, —á—Ç–æ –∏ –æ–¥–∏–Ω–æ—á–Ω—ã–µ —Å–∏–ª—å–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏.




# –ó–∞–¥–∞–Ω–∏–µ 3


–†–∞—Å—Å—á–∏—Ç–∞–π—Ç–µ –≤—ã–±–æ—Ä–∫—É –¥–ª—è –≥–∏–ø–æ—Ç–µ–∑—ã equality –¥–ª—è —Å–ª–µ–¥—É—é—â–µ–≥–æ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è. –ú—ã —Ö–æ—Ç–∏–º —Å—Ä–∞–≤–Ω–∏—Ç—å –Ω–æ–≤—É—é —Ç–µ—Ä–∞–ø–∏—é –∏–Ω—Ñ–µ–∫—Ü–∏–∏, –ø—Ä–∏—Å–æ–µ–¥–∏–Ω—è—é—â–µ–π—Å—è –≤ –±–æ–ª—å–Ω–∏—á–Ω—ã—Ö —É—Å–ª–æ–≤–∏—è—Ö —É –ø–∞—Ü–∏–µ–Ω—Ç–æ–≤ —Å –æ–∂–æ–≥–∞–º–∏, —Å –∑–æ–ª–æ—Ç—ã–º —Å—Ç–∞–Ω–¥–∞—Ä—Ç–æ–º, –æ—Å–Ω–æ–≤—ã–≤–∞—è—Å—å –Ω–∞ –¥–∞–Ω–Ω—ã—Ö, –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º—ã—Ö —Å –ø–æ–º–æ—â—å—é —Ä–µ–≥—Ä–µ—Å—Å–∏–∏ –ö–æ–∫—Å–∞. –ü—É—Å—Ç—å –æ—Ç–Ω–æ—à–µ–Ω–∏–µ —Ä–∏—Å–∫–æ–≤ ¬´–∑–æ–ª–æ—Ç–æ–π —Å—Ç–∞–Ω–¥–∞—Ä—Ç / –Ω–æ–≤–∞—è —Ç–µ—Ä–∞–ø–∏—è¬ª, hazard ratio, HR = 2. –ú—ã –ø—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ–º, —á—Ç–æ 80% –ø–∞—Ü–∏–µ–Ω—Ç–æ–≤ (d = 0,8) –º–æ–≥—É—Ç —Å—Ç–æ–ª–∫–Ω—É—Ç—å—Å—è —Å —ç—Ç–∏–º –∑–∞–±–æ–ª–µ–≤–∞–Ω–∏–µ–º. –°–æ–æ—Ç–Ω–æ—à–µ–Ω–∏—è –≥—Ä—É–ø–ø —Ç–µ—Ä–∞–ø–∏–∏ —Ä–∞–≤–Ω—ã (p1 = p2 = 0,5).

![](images/clipboard-1580076354.png)

```{r}
library(MASS)

# –ö—Ä–∏—Ç–∏—á–µ—Å–∫–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –¥–ª—è 95% –¥–æ–≤–µ—Ä–∏—Ç–µ–ª—å–Ω–æ–≥–æ –∏–Ω—Ç–µ—Ä–≤–∞–ª–∞
Z <- qnorm(0.975)  # 0.975 –ø–æ—Ç–æ–º—É —á—Ç–æ –º—ã —Å–º–æ—Ç—Ä–∏–º –Ω–∞ –æ–±–µ —Å—Ç–æ—Ä–æ–Ω—ã (–¥–≤—É—Å—Ç–æ—Ä–æ–Ω–Ω–∏–π —Ç–µ—Å—Ç)

HR <- 2    # –æ—Ç–Ω–æ—à–µ–Ω–∏–µ —Ä–∏—Å–∫–æ–≤
p1 <- 0.5  # –¥–æ–ª—è –ø–∞—Ü–∏–µ–Ω—Ç–æ–≤ –≤ –ø–µ—Ä–≤–æ–π –≥—Ä—É–ø–ø–µ
p2 <- 0.5  # –¥–æ–ª—è –ø–∞—Ü–∏–µ–Ω—Ç–æ–≤ –≤–æ –≤—Ç–æ—Ä–æ–π –≥—Ä—É–ø–ø–µ
d <- 0.8   # –¥–æ–ª—è –ø–∞—Ü–∏–µ–Ω—Ç–æ–≤, –∫–æ—Ç–æ—Ä—ã–µ –º–æ–≥—É—Ç —Å—Ç–æ–ª–∫–Ω—É—Ç—å—Å—è —Å –∑–∞–±–æ–ª–µ–≤–∞–Ω–∏–µ–º

ln_HR <- log(HR)
n_1_n_2 <- ((Z / 2 + Z) ^ 2) * (ln_HR ^ 2) * p1 * p2 * d
n_total <- n_1_n_2 * 2

# –†–µ–∑—É–ª—å—Ç–∞—Ç
cat(sprintf("–†–∞–∑–º–µ—Ä –≤—ã–±–æ—Ä–∫–∏ –¥–ª—è –∫–∞–∂–¥–æ–π –≥—Ä—É–ø–ø—ã: %.0f\n", n_1_n_2))
cat(sprintf("–û–±—â–∏–π —Ä–∞–∑–º–µ—Ä –≤—ã–±–æ—Ä–∫–∏: %.0f\n", n_total))

```

–ù–æ –≤ —Ä–µ–∞–ª—å–Ω–æ–π –ø—Ä–∞–∫—Ç–∏–∫–µ —ç—Ç–æ –ø–æ–¥–æ–∑—Ä–∏—Ç–µ–ª—å–Ω–æ –º–∞–ª–æ

–ù–∏–∑–∫–æ–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏–µ –∫ –º–æ—â–Ω–æ—Å—Ç–∏ ‚Äî –≤ —Ñ–æ—Ä–º—É–ª–µ –Ω–µ —É—á—Ç—ë–Ω –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç, –æ—Ç–≤–µ—á–∞—é—â–∏–π –∑–∞ –º–æ—â–Ω–æ—Å—Ç—å —Ç–µ—Å—Ç–∞

–§–æ—Ä–º—É–ª–∞ —É–ø—Ä–æ—â—ë–Ω–Ω–∞—è, –æ–Ω–∞ –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —Ç–æ—á–Ω–∞ –¥–ª—è —Ä–µ–∞–ª—å–Ω–æ–≥–æ —Ä–∞—Å—á—ë—Ç–∞ –≤—ã–±–æ—Ä–∫–∏ –≤ —Ä–µ–≥—Ä–µ—Å—Å–∏–∏ –ö–æ–∫—Å–∞.

HR = 2 ‚Äî —ç—Ç–æ –±–æ–ª—å—à–æ–µ —Ä–∞–∑–ª–∏—á–∏–µ –º–µ–∂–¥—É –≥—Ä—É–ø–ø–∞–º–∏. –ß–µ–º —Å–∏–ª—å–Ω–µ–µ —ç—Ñ—Ñ–µ–∫—Ç, —Ç–µ–º –º–µ–Ω—å—à–µ –≤—ã–±–æ—Ä–∫–∞ –Ω—É–∂–Ω–∞ –¥–ª—è –µ–≥–æ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è.

–ü–æ—ç—Ç–æ–º—É –≤–æ—Å–ø–æ–ª—å–∑—É–µ–º—Å—è –≥–æ—Ç–æ–≤—ã–º–∏ —Ä–µ—à–µ–Ω–∏—è–º–∏ –¥–ª—è —Ä–∞—Å—á–µ—Ç–∞ –≤—ã–±–æ—Ä–∫–∏ –≤ —Ä–µ–≥—Ä–µ—Å—Å–∏–∏ –ö–æ–∫—Å–∞



–ü–æ—Å—Ç—Ä–æ–∏–º —Å–ø–µ—Ä–≤–∞ –≥—Ä–∞—Ñ–∏–∫ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ —Ä–∞–∑–º–µ—Ä–∞ –≤—ã–±–æ—Ä–∫–∏ –æ—Ç –æ—Ç–Ω–æ—à–µ–Ω–∏—è —Ä–∏—Å–∫–æ–≤ (HR)

```{r}
library(survival)
library(ggplot2)

alpha <- 0.05
power <- 0.8
p <- 0.5
event_rate <- 0.8

hr_values <- seq(1.1, 3.0, length.out = 50)
sample_sizes <- numeric(length(hr_values))

sample_size_cph <- function(alpha, power, p, event_rate, HR) {
  log_HR <- log(HR)
  
  n_exp <- (qnorm(1 - alpha / 2) + qnorm(power))^2 * (p * (1 - p) + event_rate * (1 - event_rate)) / (log_HR^2)
  n_con <- n_exp
  
  return(n_exp + n_con)
}

for (i in 1:length(hr_values)) {
  HR <- hr_values[i]
  tryCatch({
    total_n <- sample_size_cph(alpha, power, p, event_rate, HR)
    sample_sizes[i] <- total_n
  }, error = function(e) {
    sample_sizes[i] <- NA 
  })
}


data <- data.frame(HR = hr_values, SampleSize = sample_sizes)
ggplot(data, aes(x = HR, y = SampleSize)) +
  geom_line() +
  geom_point() +
  labs(x = "Hazard Ratio (HR)", y = "–û–±—â–∏–π —Ä–∞–∑–º–µ—Ä –≤—ã–±–æ—Ä–∫–∏", title = " –ó–∞–≤–∏—Å–∏–º–æ—Å—Ç—å —Ä–∞–∑–º–µ—Ä–∞ –≤—ã–±–æ—Ä–∫–∏ –æ—Ç Hazard Ratio") +
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5)) +
  theme(panel.grid.major = element_line(color = "gray", size = 0.5), panel.grid.minor = element_blank())

```

–ì—Ä–∞—Ñ–∏–∫ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ —Ä–∞–∑–º–µ—Ä–∞ –≤—ã–±–æ—Ä–∫–∏ –æ—Ç HR –ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç, –∫–∞–∫ –º–µ–Ω—è–µ—Ç—Å—è –Ω–µ–æ–±—Ö–æ–¥–∏–º–∞—è –≤—ã–±–æ—Ä–∫–∞ –ø—Ä–∏ —Ä–∞–∑–Ω—ã—Ö —ç—Ñ—Ñ–µ–∫—Ç–∞—Ö.

–ö–æ–≥–¥–∞ HR = 1 - –≤—ã–±–æ—Ä–∫–∞ —Å—Ç—Ä–µ–º–∏—Ç—Å—è –∫ –±–µ—Å–∫–æ–Ω–µ—á–Ω–æ—Å—Ç–∏ (—Å–ª–æ–∂–Ω–æ –¥–æ–∫–∞–∑–∞—Ç—å –Ω–µ—Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π —ç—Ñ—Ñ–µ–∫—Ç).

–ö–æ–≥–¥–∞ HR –±–æ–ª—å—à–æ–π (2‚Äì3) - —Ç—Ä–µ–±—É–µ—Ç—Å—è –º–µ–Ω—å—à–µ –ø–∞—Ü–∏–µ–Ω—Ç–æ–≤, —á—Ç–æ–±—ã –≤—ã—è–≤–∏—Ç—å —ç—Ñ—Ñ–µ–∫—Ç.




–¢–∞–∫–∂–µ –ø–æ—Å—Ç—Ä–æ–∏–º –≥—Ä–∞—Ñ–∏–∫ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ —Ä–∞–∑–º–µ—Ä–∞ –≤—ã–±–æ—Ä–∫–∏ –æ—Ç –º–æ—â–Ω–æ—Å—Ç–∏ —Ç–µ—Å—Ç–∞ (power)

```{r}
library(ggplot2)

alpha <- 0.05
HR <- 2.0
log_HR <- log(HR)
p <- 0.5
event_rate <- 0.8

powers <- seq(0.6, 0.99, length.out = 40)
sample_sizes_power <- numeric(length(powers))

sample_size_power <- function(log_HR, power, alpha, p, event_rate) {
  Z <- qnorm(1 - alpha / 2) + qnorm(power)
  n <- (Z^2 * (p * (1 - p) + event_rate * (1 - event_rate))) / log_HR^2
  return(n)
}

for (i in 1:length(powers)) {
  pwr <- powers[i]
  n <- sample_size_power(log_HR, pwr, alpha, p, event_rate)
  sample_sizes_power[i] <- ceiling(n) * 2
}

data <- data.frame(Power = powers, SampleSize = sample_sizes_power)
ggplot(data, aes(x = Power, y = SampleSize)) +
  geom_line(color = "green") +
  geom_point(color = "green") +
  labs(x = "–ú–æ—â–Ω–æ—Å—Ç—å —Ç–µ—Å—Ç–∞ (Power)", y = "–û–±—â–∏–π —Ä–∞–∑–º–µ—Ä –≤—ã–±–æ—Ä–∫–∏", title = "–ó–∞–≤–∏—Å–∏–º–æ—Å—Ç—å —Ä–∞–∑–º–µ—Ä–∞ –≤—ã–±–æ—Ä–∫–∏ –æ—Ç –º–æ—â–Ω–æ—Å—Ç–∏ —Ç–µ—Å—Ç–∞") +
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5)) +
  theme(panel.grid.major = element_line(color = "gray", size = 0.5), panel.grid.minor = element_blank())

```

–ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç, –∫–∞–∫ —Å–∏–ª—å–Ω–æ –≤–ª–∏—è–µ—Ç —Ç—Ä–µ–±—É–µ–º–∞—è –º–æ—â–Ω–æ—Å—Ç—å —Ç–µ—Å—Ç–∞.

–ß–µ–º –≤—ã—à–µ –º–æ—â–Ω–æ—Å—Ç—å - —Ç–µ–º –±–æ–ª—å—à–µ –≤—ã–±–æ—Ä–∫–∞ –Ω—É–∂–Ω–∞, —á—Ç–æ–±—ã –Ω–µ –ø—Ä–æ–ø—É—Å—Ç–∏—Ç—å —ç—Ñ—Ñ–µ–∫—Ç. Power = 0.8 (80%) - —Å—Ç–∞–Ω–¥–∞—Ä—Ç –≤ –º–µ–¥–∏—Ü–∏–Ω–µ.



–° –∏—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å—Å–∫–æ–π —Ç–æ—á–∫–∏ –∑—Ä–µ–Ω–∏—è –Ω–∞–º –±—ã–ª–æ –±—ã –∏–Ω—Ç–µ—Ä–µ—Å—Å–Ω–æ –ø–µ—Ä–µ–±—Ä–∞—Ç—å —Ä–∞–∑–Ω—ã–µ –Ω–∞–±–æ—Ä—ã –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤, –ø–æ—ç—Ç–æ–º—É —Ä–µ–∞–ª–∏–∑—É–µ–º —Å–ø–µ—Ä–≤–∞ —Å–∞–º–æ–ø–∏—Å–Ω—ã–π –ø–µ—Ä–µ–±–æ—Ä grid search, –∞ –∑–∞—Ç–µ–º –≤–æ—Å–ø–æ–ª—å–∑—É–µ–º—Å—è –≥–æ—Ç–æ–≤—ã–º —Ä–µ—à–µ–Ω–∏–µ–º –∏ —Å—Ä–∞–≤–Ω–∏–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã

```{r}
library(dplyr)
library(tidyr)

sample_size_necessary <- function(hr, power, alpha, p_exp, p_con, ratio_of_participants) {
  Z <- qnorm(1 - alpha / 2) + qnorm(power)
  log_HR <- log(hr)
  n1_n2 <- (Z^2 * (p_exp * (1 - p_exp) + p_con * (1 - p_con))) / log_HR^2
  return(n1_n2)
}

hr_values <- seq(1.1, 3.0, by = 0.2)
power_values <- c(0.8, 0.85, 0.9)
event_rates <- c(0.6, 0.7, 0.8, 0.9)
alpha <- 0.05
p <- 0.5
ratio_of_participants <- 1

results <- list()

for (hr in hr_values) {
  for (power in power_values) {
    for (event_rate in event_rates) {
      tryCatch({
        n1_n2 <- sample_size_necessary(hr, power, alpha, p, p, ratio_of_participants)
        sample_size <- n1_n2 * 2
        adjusted_sample_size <- ceiling(sample_size / event_rate)
  
        results <- append(results, list(data.frame(
          HR = round(hr, 2),
          Power = power,
          Event_Rate = event_rate,
          Raw_Sample_Size = ceiling(sample_size),
          Adjusted_Sample_Size = adjusted_sample_size
        )))
      }, error = function(e) {
        cat("–û—à–∏–±–∫–∞ –ø—Ä–∏ HR =", hr, ", power =", power, ", event_rate =", event_rate, ": ", e$message, "\n")
      })
    }
  }
}

df_results <- bind_rows(results)

df_sorted <- df_results %>% arrange(Adjusted_Sample_Size)

print(head(df_sorted, 10))

```

```{r}
library(powerSurvEpi)
library(nloptr)

objective_function <- function(params) {
  hr <- params[1]
  power <- params[2]
  pC <- params[3]
  
  alpha <- 0.05
  ratio <- 1
  p <- 0.5
  
  tryCatch({
    sample_size <- ssizeCT.default(
      power = power,
      k = ratio,
      pE = pC * hr,
      pC = pC,
      RR = hr,
      alpha = alpha
    )
    adjusted_sample_size <- ceiling(sample_size)
    return(adjusted_sample_size)
  }, error = function(e) {
    print(paste("–û—à–∏–±–∫–∞ –≤ —Ä–∞—Å—á–µ—Ç–∞—Ö:", e$message))
    return(Inf)
  })
}


lower_bounds <- c(1.1, 0.8, 0.6)
upper_bounds <- c(3.1, 0.85, 0.9)

result <- nloptr::nloptr(
  x0 = c(1.5, 0.825, 0.75),
  eval_f = objective_function,
  lb = lower_bounds,
  ub = upper_bounds,
  opts = list(algorithm = "NLOPT_GN_CRS2_LM", maxeval = 100)
)

if (result$objective < Inf) {
  print(paste("–õ—É—á—à–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã (HR, power, pC):", paste(round(result$solution, 3), collapse = ", ")))
  print(paste("–ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä –≤—ã–±–æ—Ä–∫–∏:", result$objective))
} else {
  print("–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –Ω–µ —É–¥–∞–ª–∞—Å—å. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∏ —Ü–µ–ª–µ–≤—É—é —Ñ—É–Ω–∫—Ü–∏—é.")
}

```

–ö–∞–∫ –º—ã –≤–∏–¥–∏–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏ —Å–æ—à–ª–∏—Å—å, —Ä—É—á–Ω–æ–π –ø–æ–¥–±–æ—Ä –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –ø—Ä–µ–¥–ª–æ–∂–∏–ª —Å–ª–µ–¥—É—é—â–∏–π –Ω–∞–±–æ—Ä –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤:

```         
  HR    Power   Event Rate     Adjusted Sample Size
  2.9   0.80    0.9            8
```

–í —Ç–æ –≤—Ä–µ–º—è –∫–∞–∫ –≤—Å—Ç—Ä–æ–µ–Ω–Ω—ã–π –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä –ø—Ä–µ–¥–ª–æ–∂–∏–ª —Ç–∞–∫–∏–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã

```         
  HR     Power   Event Rate    Adjusted Sample Size
  3.1   0.83    0.9            9
```
